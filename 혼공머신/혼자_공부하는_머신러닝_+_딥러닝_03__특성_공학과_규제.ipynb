{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "혼자_공부하는_머신러닝_+_딥러닝_03__특성_공학과_규제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN6YKJcJ7gfseToJ4/M4thm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leena-GO/Self-study/blob/main/%ED%98%BC%EA%B3%B5%EB%A8%B8%EC%8B%A0/%ED%98%BC%EC%9E%90_%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%2B_%EB%94%A5%EB%9F%AC%EB%8B%9D_03__%ED%8A%B9%EC%84%B1_%EA%B3%B5%ED%95%99%EA%B3%BC_%EA%B7%9C%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_LOVpWVHAND"
      },
      "source": [
        "# 03-3 특성 공학과 규제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqBTmrN7HMcV"
      },
      "source": [
        "- 앞서 공부했던 *다항 회귀*에서, 훈련 세트보다 테스트 세트의 점수가 높은 **과소 적합**의 문제가 있었다.\n",
        "- 이를 해결하기 위해, **다중 회귀**를 사용해본다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4xHUD-FJtUl"
      },
      "source": [
        "## 1. 다중 회귀(Multiple Regression)\n",
        "- **다중회귀**: 여러 개의 특성을 사용한 선형 회귀\n",
        "  - 2개의 특성을 사용하면, 선형회귀는 *평면(3차원)*을 학습하게 된다.\n",
        "  - *타깃 = (a x 특성1) + (b x 특성2) + 절편* \n",
        "\n",
        "- 위 식과 같이, 기존의 특성을 사용하여 새로운 특성을 뽑아내는 작업을 **특성 공학**(Feature Engineering)이라고 한다.\n",
        "\n",
        "\n",
        "---\n",
        "- 특성이 3개로 늘어났기 때문에, numpy 대신 pandas DataFrame을 사용하여 데이터를 활용하도록 한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BskSNykWJwrq"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://bit.ly/perch_csv')\n",
        "perch_full = df.to_numpy() #DataFrame을 numpy 배열로 바꿔주는 메서드"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EVpxLH85LhJP",
        "outputId": "e3bfba58-95c8-4c89-b9be-3390f72e683a"
      },
      "source": [
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.4</td>\n",
              "      <td>2.11</td>\n",
              "      <td>1.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.7</td>\n",
              "      <td>3.53</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15.0</td>\n",
              "      <td>3.82</td>\n",
              "      <td>2.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.2</td>\n",
              "      <td>4.59</td>\n",
              "      <td>2.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.4</td>\n",
              "      <td>4.59</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>18.0</td>\n",
              "      <td>5.22</td>\n",
              "      <td>3.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>18.7</td>\n",
              "      <td>5.20</td>\n",
              "      <td>3.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>19.0</td>\n",
              "      <td>5.64</td>\n",
              "      <td>3.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>19.6</td>\n",
              "      <td>5.14</td>\n",
              "      <td>3.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20.0</td>\n",
              "      <td>5.08</td>\n",
              "      <td>2.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>21.0</td>\n",
              "      <td>5.69</td>\n",
              "      <td>3.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>21.0</td>\n",
              "      <td>5.92</td>\n",
              "      <td>3.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>21.0</td>\n",
              "      <td>5.69</td>\n",
              "      <td>3.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>21.3</td>\n",
              "      <td>6.38</td>\n",
              "      <td>3.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6.11</td>\n",
              "      <td>3.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>22.0</td>\n",
              "      <td>5.64</td>\n",
              "      <td>3.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6.11</td>\n",
              "      <td>3.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>22.0</td>\n",
              "      <td>5.88</td>\n",
              "      <td>3.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>22.0</td>\n",
              "      <td>5.52</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>22.5</td>\n",
              "      <td>5.86</td>\n",
              "      <td>3.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>22.5</td>\n",
              "      <td>6.79</td>\n",
              "      <td>3.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22.7</td>\n",
              "      <td>5.95</td>\n",
              "      <td>3.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23.0</td>\n",
              "      <td>5.22</td>\n",
              "      <td>3.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23.5</td>\n",
              "      <td>6.28</td>\n",
              "      <td>3.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24.0</td>\n",
              "      <td>7.29</td>\n",
              "      <td>3.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>24.0</td>\n",
              "      <td>6.38</td>\n",
              "      <td>3.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>24.6</td>\n",
              "      <td>6.73</td>\n",
              "      <td>4.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>25.0</td>\n",
              "      <td>6.44</td>\n",
              "      <td>3.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>25.6</td>\n",
              "      <td>6.56</td>\n",
              "      <td>4.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>26.5</td>\n",
              "      <td>7.17</td>\n",
              "      <td>4.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>27.3</td>\n",
              "      <td>8.32</td>\n",
              "      <td>5.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>27.5</td>\n",
              "      <td>7.17</td>\n",
              "      <td>4.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>27.5</td>\n",
              "      <td>7.05</td>\n",
              "      <td>4.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>27.5</td>\n",
              "      <td>7.28</td>\n",
              "      <td>4.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>28.0</td>\n",
              "      <td>7.82</td>\n",
              "      <td>4.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>28.7</td>\n",
              "      <td>7.59</td>\n",
              "      <td>4.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>30.0</td>\n",
              "      <td>7.62</td>\n",
              "      <td>4.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>32.8</td>\n",
              "      <td>10.03</td>\n",
              "      <td>6.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>34.5</td>\n",
              "      <td>10.26</td>\n",
              "      <td>6.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>35.0</td>\n",
              "      <td>11.49</td>\n",
              "      <td>7.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>36.5</td>\n",
              "      <td>10.88</td>\n",
              "      <td>6.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>36.0</td>\n",
              "      <td>10.61</td>\n",
              "      <td>6.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>37.0</td>\n",
              "      <td>10.84</td>\n",
              "      <td>6.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>37.0</td>\n",
              "      <td>10.57</td>\n",
              "      <td>6.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>39.0</td>\n",
              "      <td>11.14</td>\n",
              "      <td>7.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>39.0</td>\n",
              "      <td>11.14</td>\n",
              "      <td>6.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>39.0</td>\n",
              "      <td>12.43</td>\n",
              "      <td>7.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>40.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>7.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>40.0</td>\n",
              "      <td>11.73</td>\n",
              "      <td>7.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>40.0</td>\n",
              "      <td>12.38</td>\n",
              "      <td>7.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>40.0</td>\n",
              "      <td>11.14</td>\n",
              "      <td>6.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>42.0</td>\n",
              "      <td>12.80</td>\n",
              "      <td>6.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>43.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>7.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>43.0</td>\n",
              "      <td>12.51</td>\n",
              "      <td>7.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>43.5</td>\n",
              "      <td>12.60</td>\n",
              "      <td>8.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>44.0</td>\n",
              "      <td>12.49</td>\n",
              "      <td>7.60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    length   height   width\n",
              "0      8.4     2.11    1.41\n",
              "1     13.7     3.53    2.00\n",
              "2     15.0     3.82    2.43\n",
              "3     16.2     4.59    2.63\n",
              "4     17.4     4.59    2.94\n",
              "5     18.0     5.22    3.32\n",
              "6     18.7     5.20    3.12\n",
              "7     19.0     5.64    3.05\n",
              "8     19.6     5.14    3.04\n",
              "9     20.0     5.08    2.77\n",
              "10    21.0     5.69    3.56\n",
              "11    21.0     5.92    3.31\n",
              "12    21.0     5.69    3.67\n",
              "13    21.3     6.38    3.53\n",
              "14    22.0     6.11    3.41\n",
              "15    22.0     5.64    3.52\n",
              "16    22.0     6.11    3.52\n",
              "17    22.0     5.88    3.52\n",
              "18    22.0     5.52    4.00\n",
              "19    22.5     5.86    3.62\n",
              "20    22.5     6.79    3.62\n",
              "21    22.7     5.95    3.63\n",
              "22    23.0     5.22    3.63\n",
              "23    23.5     6.28    3.72\n",
              "24    24.0     7.29    3.72\n",
              "25    24.0     6.38    3.82\n",
              "26    24.6     6.73    4.17\n",
              "27    25.0     6.44    3.68\n",
              "28    25.6     6.56    4.24\n",
              "29    26.5     7.17    4.14\n",
              "30    27.3     8.32    5.14\n",
              "31    27.5     7.17    4.34\n",
              "32    27.5     7.05    4.34\n",
              "33    27.5     7.28    4.57\n",
              "34    28.0     7.82    4.20\n",
              "35    28.7     7.59    4.64\n",
              "36    30.0     7.62    4.77\n",
              "37    32.8    10.03    6.02\n",
              "38    34.5    10.26    6.39\n",
              "39    35.0    11.49    7.80\n",
              "40    36.5    10.88    6.86\n",
              "41    36.0    10.61    6.74\n",
              "42    37.0    10.84    6.26\n",
              "43    37.0    10.57    6.37\n",
              "44    39.0    11.14    7.49\n",
              "45    39.0    11.14    6.00\n",
              "46    39.0    12.43    7.35\n",
              "47    40.0    11.93    7.11\n",
              "48    40.0    11.73    7.22\n",
              "49    40.0    12.38    7.46\n",
              "50    40.0    11.14    6.63\n",
              "51    42.0    12.80    6.87\n",
              "52    43.0    11.93    7.28\n",
              "53    43.0    12.51    7.42\n",
              "54    43.5    12.60    8.14\n",
              "55    44.0    12.49    7.60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfv-gO72Lj4D",
        "outputId": "b4d0eda4-022b-4c16-c776-e3edfa0be2c7"
      },
      "source": [
        "perch_full"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 8.4 ,  2.11,  1.41],\n",
              "       [13.7 ,  3.53,  2.  ],\n",
              "       [15.  ,  3.82,  2.43],\n",
              "       [16.2 ,  4.59,  2.63],\n",
              "       [17.4 ,  4.59,  2.94],\n",
              "       [18.  ,  5.22,  3.32],\n",
              "       [18.7 ,  5.2 ,  3.12],\n",
              "       [19.  ,  5.64,  3.05],\n",
              "       [19.6 ,  5.14,  3.04],\n",
              "       [20.  ,  5.08,  2.77],\n",
              "       [21.  ,  5.69,  3.56],\n",
              "       [21.  ,  5.92,  3.31],\n",
              "       [21.  ,  5.69,  3.67],\n",
              "       [21.3 ,  6.38,  3.53],\n",
              "       [22.  ,  6.11,  3.41],\n",
              "       [22.  ,  5.64,  3.52],\n",
              "       [22.  ,  6.11,  3.52],\n",
              "       [22.  ,  5.88,  3.52],\n",
              "       [22.  ,  5.52,  4.  ],\n",
              "       [22.5 ,  5.86,  3.62],\n",
              "       [22.5 ,  6.79,  3.62],\n",
              "       [22.7 ,  5.95,  3.63],\n",
              "       [23.  ,  5.22,  3.63],\n",
              "       [23.5 ,  6.28,  3.72],\n",
              "       [24.  ,  7.29,  3.72],\n",
              "       [24.  ,  6.38,  3.82],\n",
              "       [24.6 ,  6.73,  4.17],\n",
              "       [25.  ,  6.44,  3.68],\n",
              "       [25.6 ,  6.56,  4.24],\n",
              "       [26.5 ,  7.17,  4.14],\n",
              "       [27.3 ,  8.32,  5.14],\n",
              "       [27.5 ,  7.17,  4.34],\n",
              "       [27.5 ,  7.05,  4.34],\n",
              "       [27.5 ,  7.28,  4.57],\n",
              "       [28.  ,  7.82,  4.2 ],\n",
              "       [28.7 ,  7.59,  4.64],\n",
              "       [30.  ,  7.62,  4.77],\n",
              "       [32.8 , 10.03,  6.02],\n",
              "       [34.5 , 10.26,  6.39],\n",
              "       [35.  , 11.49,  7.8 ],\n",
              "       [36.5 , 10.88,  6.86],\n",
              "       [36.  , 10.61,  6.74],\n",
              "       [37.  , 10.84,  6.26],\n",
              "       [37.  , 10.57,  6.37],\n",
              "       [39.  , 11.14,  7.49],\n",
              "       [39.  , 11.14,  6.  ],\n",
              "       [39.  , 12.43,  7.35],\n",
              "       [40.  , 11.93,  7.11],\n",
              "       [40.  , 11.73,  7.22],\n",
              "       [40.  , 12.38,  7.46],\n",
              "       [40.  , 11.14,  6.63],\n",
              "       [42.  , 12.8 ,  6.87],\n",
              "       [43.  , 11.93,  7.28],\n",
              "       [43.  , 12.51,  7.42],\n",
              "       [43.5 , 12.6 ,  8.14],\n",
              "       [44.  , 12.49,  7.6 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkKelE7yJwpm"
      },
      "source": [
        "#타깃 데이터 준비\n",
        "import numpy as np\n",
        "\n",
        "#농어의 특성을 활용하여 무게를 예측하는 작업이기 때문에, 타깃 데이터가 되는 무게만 가지고 온다.\n",
        "perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,\n",
        "       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,\n",
        "       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,\n",
        "       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,\n",
        "       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,\n",
        "       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,\n",
        "       1000.0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKwbsrsaLsbj"
      },
      "source": [
        "#perch_full과 perch_weight을 훈련 세트와 테스트 세트로 나눠주기\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train_input, train_target, test_input, test_target = train_test_split(perch_full, perch_weight, random_state = 42)\n",
        "train_input, test_input, train_target, test_target = train_test_split(perch_full, perch_weight, random_state = 42)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP7K8zGbx3Vq"
      },
      "source": [
        "- 정말 크게 깨달은 점: input 데이터와 target 데이터의 순서를 달리 하면, 문제가 생긴다ㅠㅠ\n",
        "  - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFGdZP1GwBHi",
        "outputId": "2ea564d3-af5c-4b77-b477-e0bf659e971d"
      },
      "source": [
        "train_input"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19.6 ,  5.14,  3.04],\n",
              "       [22.  ,  5.88,  3.52],\n",
              "       [18.7 ,  5.2 ,  3.12],\n",
              "       [17.4 ,  4.59,  2.94],\n",
              "       [36.  , 10.61,  6.74],\n",
              "       [25.  ,  6.44,  3.68],\n",
              "       [40.  , 11.93,  7.11],\n",
              "       [39.  , 12.43,  7.35],\n",
              "       [43.  , 11.93,  7.28],\n",
              "       [22.  ,  5.64,  3.52],\n",
              "       [20.  ,  5.08,  2.77],\n",
              "       [22.  ,  6.11,  3.52],\n",
              "       [24.  ,  7.29,  3.72],\n",
              "       [27.5 ,  7.17,  4.34],\n",
              "       [43.  , 12.51,  7.42],\n",
              "       [40.  , 11.73,  7.22],\n",
              "       [24.  ,  6.38,  3.82],\n",
              "       [21.  ,  5.92,  3.31],\n",
              "       [27.5 ,  7.05,  4.34],\n",
              "       [40.  , 12.38,  7.46],\n",
              "       [32.8 , 10.03,  6.02],\n",
              "       [26.5 ,  7.17,  4.14],\n",
              "       [36.5 , 10.88,  6.86],\n",
              "       [13.7 ,  3.53,  2.  ],\n",
              "       [22.7 ,  5.95,  3.63],\n",
              "       [15.  ,  3.82,  2.43],\n",
              "       [37.  , 10.57,  6.37],\n",
              "       [35.  , 11.49,  7.8 ],\n",
              "       [28.7 ,  7.59,  4.64],\n",
              "       [23.5 ,  6.28,  3.72],\n",
              "       [39.  , 11.14,  6.  ],\n",
              "       [21.  ,  5.69,  3.56],\n",
              "       [23.  ,  5.22,  3.63],\n",
              "       [22.  ,  5.52,  4.  ],\n",
              "       [44.  , 12.49,  7.6 ],\n",
              "       [22.5 ,  6.79,  3.62],\n",
              "       [19.  ,  5.64,  3.05],\n",
              "       [37.  , 10.84,  6.26],\n",
              "       [22.  ,  6.11,  3.41],\n",
              "       [25.6 ,  6.56,  4.24],\n",
              "       [42.  , 12.8 ,  6.87],\n",
              "       [34.5 , 10.26,  6.39]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWmWTHUJwMnu",
        "outputId": "348d2406-39ea-48ae-a5d1-1145cf1ce374"
      },
      "source": [
        "train_target"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 8.4 ,  2.11,  1.41],\n",
              "       [18.  ,  5.22,  3.32],\n",
              "       [27.5 ,  7.28,  4.57],\n",
              "       [21.3 ,  6.38,  3.53],\n",
              "       [22.5 ,  5.86,  3.62],\n",
              "       [40.  , 11.14,  6.63],\n",
              "       [30.  ,  7.62,  4.77],\n",
              "       [24.6 ,  6.73,  4.17],\n",
              "       [39.  , 11.14,  7.49],\n",
              "       [21.  ,  5.69,  3.67],\n",
              "       [43.5 , 12.6 ,  8.14],\n",
              "       [16.2 ,  4.59,  2.63],\n",
              "       [28.  ,  7.82,  4.2 ],\n",
              "       [27.3 ,  8.32,  5.14]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTblr3A5v_Sy",
        "outputId": "0f020e43-a005-456c-e0c8-eae88a11776a"
      },
      "source": [
        "test_input"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  85.,  135.,   78.,   70.,  700.,  180.,  850.,  820., 1000.,\n",
              "        120.,   85.,  130.,  225.,  260., 1100.,  900.,  145.,  115.,\n",
              "        265., 1015.,  514.,  218.,  685.,   32.,  145.,   40.,  690.,\n",
              "        840.,  300.,  170.,  650.,  110.,  150.,  110., 1000.,  150.,\n",
              "         80.,  700.,  120.,  197., 1100.,  556.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtM0-jcMwON8",
        "outputId": "2df9e7ae-8bb8-4951-ce3c-6b4a4a6aec71"
      },
      "source": [
        "test_target"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   5.9,  100. ,  250. ,  130. ,  130. ,  820. ,  320. ,  188. ,\n",
              "        900. ,  125. , 1000. ,   51.5,  250. ,  300. ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paCEKCJvyKpy"
      },
      "source": [
        "- test_input이 'perch_full' 데이터를 활용하여 input 데이터가 되어야 하는데, 순서가 바뀌어서 이런 문제가 발생하게 된 것..!!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "a5ymxLz5uiIz",
        "outputId": "2d160aa1-e26c-4b4e-9c18-e9abf09edb8d"
      },
      "source": [
        "test_poly = poly.transform(test_input)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-a75818d90443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_poly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m         X = check_array(X, order='F', dtype=FLOAT_DTYPES,\n\u001b[0;32m-> 1546\u001b[0;31m                         accept_sparse=('csr', 'csc'))\n\u001b[0m\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[  85.  135.   78.   70.  700.  180.  850.  820. 1000.  120.   85.  130.\n  225.  260. 1100.  900.  145.  115.  265. 1015.  514.  218.  685.   32.\n  145.   40.  690.  840.  300.  170.  650.  110.  150.  110. 1000.  150.\n   80.  700.  120.  197. 1100.  556.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrc17rggL-xW"
      },
      "source": [
        "## 2. 사이킷런의 변환기\n",
        "- 사이킷런은 **특성을 만들**거나, **전처리**하기 위한 다양한 클래스를 제공하는데, 이러한 클래스를 **변환기**(transformer)라고 한다.\n",
        "  - 변환기 클래스는 모두 **fit()**, **transform()** 메서드를 제공한다.\n",
        "  - 앞서 배운 LinearRegression 같은 사이킷런 모델 클래스는 **추정기**(estimator)라고 한다.\n",
        "\n",
        "\n",
        "\n",
        "  - 이번 공부에서는 **PolynomialFeatures**클래스를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "810MkE2PGrLf",
        "outputId": "01564d1f-7feb-45c0-f196-63afc2418216"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly = PolynomialFeatures()\n",
        "\n",
        "#테스트로, 2개의 특성 2와 3으로 이루어진 샘플 하나를 적용해보자.\n",
        "poly.fit([[2,3]])\n",
        "poly.transform([[2,3]])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2., 3., 4., 6., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ND1D2bvM-rK"
      },
      "source": [
        "- 변환기(transformer)는 타깃 데이터가 필요하지 않다.\n",
        "  - 예) k-최근접이웃 회귀에서는 **knr.fit(train_input, train_target)** 과 같이, 타깃 데이터를 넣어주었다.\n",
        "\n",
        "\n",
        "- 위에서 보다시피, 2개의 특성(원소)을 가진 샘플 [2,3]이 6개의 특성을 가진 샘플 [1,2,3,4,6,9]로, 특성이 많아졌다!\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "- PolynomialFeatures 클래스는 기본적으로 각 특성을 제곱한 항을 추가하고, 특성끼리 서로 곱한 항을 추가한다.\n",
        "\n",
        "\n",
        "\n",
        "- 위의 상황에서, 1은 왜 추가가 된 것일까?\n",
        "  - 선형 방정식의 절편은, 항상 값이 1인 특성과 곱해지는 계수로 볼 수 있다.\n",
        "  - 사이킷런의 선형 모델은 자동으로 절편을 추가하므로, 굳이 1을 필요로 하지 않는다.\n",
        "  - **include_bias = False**로 지정하여 특성을 변환해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh6cPyUbudX_"
      },
      "source": [
        "Generate polynomial and interaction features.\n",
        "\n",
        "Generate a new feature matrix consisting of all polynomial combinations\n",
        "of the features with degree less than or equal to the specified degree.\n",
        "For example, if an input sample is two dimensional and of the form\n",
        "[a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].\n",
        "\n",
        "Parameters\n",
        "\n",
        "degree : integer\n",
        "    The degree of the polynomial features. Default = 2.\n",
        "\n",
        "interaction_only : boolean, default = False\n",
        "    If true, only interaction features are produced: features that are\n",
        "    products of at most degree distinct input features (so not\n",
        "    x[1] ** 2, x[0] * x[2] ** 3, etc.).\n",
        "\n",
        "include_bias : boolean\n",
        "    If True (default), then include a bias column, the feature in which\n",
        "    all polynomial powers are zero (i.e. a column of ones - acts as an\n",
        "    intercept term in a linear model).\n",
        "\n",
        "order : str in {'C', 'F'}, default 'C'\n",
        "    Order of output array in the dense case. 'F' order is faster to\n",
        "    compute, but may slow down subsequent estimators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1yRCFAPM6HB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c0bfbd-97be-4bb9-d34e-4bc8ea4d7a36"
      },
      "source": [
        "poly = PolynomialFeatures(include_bias = False)\n",
        "\n",
        "poly.fit([[2,3]])\n",
        "poly.transform([[2,3]])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 3., 4., 6., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EzqoWwWutge"
      },
      "source": [
        "- 이렇게, 절편을 위한 항이 제거되고, 특성의 제곱과 특성끼리 곱한 항만 추가가 되었다.\n",
        "- 이 방식으로 *train_input*에 적용해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETYSGiDkutSr",
        "outputId": "9583fe29-16ce-45e9-ea98-8967217fe6a5"
      },
      "source": [
        "poly = PolynomialFeatures(include_bias = False)\n",
        "\n",
        "poly.fit(train_input)\n",
        "train_poly = poly.transform(train_input)\n",
        "train_poly.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySO3p8fVvd-3",
        "outputId": "04aaf889-29cd-494d-ad12-1447cc43382e"
      },
      "source": [
        "#train_input의 총 len은 42개\n",
        "len(train_input)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVztsg-KulmC",
        "outputId": "ac854bb5-f5e9-42bb-8887-5d4af6777b33"
      },
      "source": [
        "#위 9개 특성이 어떻게 만들어졌는지 확인하는 방법: get_feature_names()\n",
        "poly.get_feature_names()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x0', 'x1', 'x2', 'x0^2', 'x0 x1', 'x0 x2', 'x1^2', 'x1 x2', 'x2^2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA9ANU5TzKr3",
        "outputId": "afb5003e-5aae-4bea-ac90-e9d4d52b1c08"
      },
      "source": [
        "#기존에 있던 3개의 특성을 가지고, 위의 방법으로 9개의 특성까지 만들어냈다.\n",
        "train_poly"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  19.6   ,    5.14  ,    3.04  ,  384.16  ,  100.744 ,   59.584 ,\n",
              "          26.4196,   15.6256,    9.2416],\n",
              "       [  22.    ,    5.88  ,    3.52  ,  484.    ,  129.36  ,   77.44  ,\n",
              "          34.5744,   20.6976,   12.3904],\n",
              "       [  18.7   ,    5.2   ,    3.12  ,  349.69  ,   97.24  ,   58.344 ,\n",
              "          27.04  ,   16.224 ,    9.7344],\n",
              "       [  17.4   ,    4.59  ,    2.94  ,  302.76  ,   79.866 ,   51.156 ,\n",
              "          21.0681,   13.4946,    8.6436],\n",
              "       [  36.    ,   10.61  ,    6.74  , 1296.    ,  381.96  ,  242.64  ,\n",
              "         112.5721,   71.5114,   45.4276],\n",
              "       [  25.    ,    6.44  ,    3.68  ,  625.    ,  161.    ,   92.    ,\n",
              "          41.4736,   23.6992,   13.5424],\n",
              "       [  40.    ,   11.93  ,    7.11  , 1600.    ,  477.2   ,  284.4   ,\n",
              "         142.3249,   84.8223,   50.5521],\n",
              "       [  39.    ,   12.43  ,    7.35  , 1521.    ,  484.77  ,  286.65  ,\n",
              "         154.5049,   91.3605,   54.0225],\n",
              "       [  43.    ,   11.93  ,    7.28  , 1849.    ,  512.99  ,  313.04  ,\n",
              "         142.3249,   86.8504,   52.9984],\n",
              "       [  22.    ,    5.64  ,    3.52  ,  484.    ,  124.08  ,   77.44  ,\n",
              "          31.8096,   19.8528,   12.3904],\n",
              "       [  20.    ,    5.08  ,    2.77  ,  400.    ,  101.6   ,   55.4   ,\n",
              "          25.8064,   14.0716,    7.6729],\n",
              "       [  22.    ,    6.11  ,    3.52  ,  484.    ,  134.42  ,   77.44  ,\n",
              "          37.3321,   21.5072,   12.3904],\n",
              "       [  24.    ,    7.29  ,    3.72  ,  576.    ,  174.96  ,   89.28  ,\n",
              "          53.1441,   27.1188,   13.8384],\n",
              "       [  27.5   ,    7.17  ,    4.34  ,  756.25  ,  197.175 ,  119.35  ,\n",
              "          51.4089,   31.1178,   18.8356],\n",
              "       [  43.    ,   12.51  ,    7.42  , 1849.    ,  537.93  ,  319.06  ,\n",
              "         156.5001,   92.8242,   55.0564],\n",
              "       [  40.    ,   11.73  ,    7.22  , 1600.    ,  469.2   ,  288.8   ,\n",
              "         137.5929,   84.6906,   52.1284],\n",
              "       [  24.    ,    6.38  ,    3.82  ,  576.    ,  153.12  ,   91.68  ,\n",
              "          40.7044,   24.3716,   14.5924],\n",
              "       [  21.    ,    5.92  ,    3.31  ,  441.    ,  124.32  ,   69.51  ,\n",
              "          35.0464,   19.5952,   10.9561],\n",
              "       [  27.5   ,    7.05  ,    4.34  ,  756.25  ,  193.875 ,  119.35  ,\n",
              "          49.7025,   30.597 ,   18.8356],\n",
              "       [  40.    ,   12.38  ,    7.46  , 1600.    ,  495.2   ,  298.4   ,\n",
              "         153.2644,   92.3548,   55.6516],\n",
              "       [  32.8   ,   10.03  ,    6.02  , 1075.84  ,  328.984 ,  197.456 ,\n",
              "         100.6009,   60.3806,   36.2404],\n",
              "       [  26.5   ,    7.17  ,    4.14  ,  702.25  ,  190.005 ,  109.71  ,\n",
              "          51.4089,   29.6838,   17.1396],\n",
              "       [  36.5   ,   10.88  ,    6.86  , 1332.25  ,  397.12  ,  250.39  ,\n",
              "         118.3744,   74.6368,   47.0596],\n",
              "       [  13.7   ,    3.53  ,    2.    ,  187.69  ,   48.361 ,   27.4   ,\n",
              "          12.4609,    7.06  ,    4.    ],\n",
              "       [  22.7   ,    5.95  ,    3.63  ,  515.29  ,  135.065 ,   82.401 ,\n",
              "          35.4025,   21.5985,   13.1769],\n",
              "       [  15.    ,    3.82  ,    2.43  ,  225.    ,   57.3   ,   36.45  ,\n",
              "          14.5924,    9.2826,    5.9049],\n",
              "       [  37.    ,   10.57  ,    6.37  , 1369.    ,  391.09  ,  235.69  ,\n",
              "         111.7249,   67.3309,   40.5769],\n",
              "       [  35.    ,   11.49  ,    7.8   , 1225.    ,  402.15  ,  273.    ,\n",
              "         132.0201,   89.622 ,   60.84  ],\n",
              "       [  28.7   ,    7.59  ,    4.64  ,  823.69  ,  217.833 ,  133.168 ,\n",
              "          57.6081,   35.2176,   21.5296],\n",
              "       [  23.5   ,    6.28  ,    3.72  ,  552.25  ,  147.58  ,   87.42  ,\n",
              "          39.4384,   23.3616,   13.8384],\n",
              "       [  39.    ,   11.14  ,    6.    , 1521.    ,  434.46  ,  234.    ,\n",
              "         124.0996,   66.84  ,   36.    ],\n",
              "       [  21.    ,    5.69  ,    3.56  ,  441.    ,  119.49  ,   74.76  ,\n",
              "          32.3761,   20.2564,   12.6736],\n",
              "       [  23.    ,    5.22  ,    3.63  ,  529.    ,  120.06  ,   83.49  ,\n",
              "          27.2484,   18.9486,   13.1769],\n",
              "       [  22.    ,    5.52  ,    4.    ,  484.    ,  121.44  ,   88.    ,\n",
              "          30.4704,   22.08  ,   16.    ],\n",
              "       [  44.    ,   12.49  ,    7.6   , 1936.    ,  549.56  ,  334.4   ,\n",
              "         156.0001,   94.924 ,   57.76  ],\n",
              "       [  22.5   ,    6.79  ,    3.62  ,  506.25  ,  152.775 ,   81.45  ,\n",
              "          46.1041,   24.5798,   13.1044],\n",
              "       [  19.    ,    5.64  ,    3.05  ,  361.    ,  107.16  ,   57.95  ,\n",
              "          31.8096,   17.202 ,    9.3025],\n",
              "       [  37.    ,   10.84  ,    6.26  , 1369.    ,  401.08  ,  231.62  ,\n",
              "         117.5056,   67.8584,   39.1876],\n",
              "       [  22.    ,    6.11  ,    3.41  ,  484.    ,  134.42  ,   75.02  ,\n",
              "          37.3321,   20.8351,   11.6281],\n",
              "       [  25.6   ,    6.56  ,    4.24  ,  655.36  ,  167.936 ,  108.544 ,\n",
              "          43.0336,   27.8144,   17.9776],\n",
              "       [  42.    ,   12.8   ,    6.87  , 1764.    ,  537.6   ,  288.54  ,\n",
              "         163.84  ,   87.936 ,   47.1969],\n",
              "       [  34.5   ,   10.26  ,    6.39  , 1190.25  ,  353.97  ,  220.455 ,\n",
              "         105.2676,   65.5614,   40.8321]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yB64BH6vsMy"
      },
      "source": [
        "#테스트 세트 변환하기\n",
        "test_poly = poly.transform(test_input)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMzbyDs7ycTQ"
      },
      "source": [
        "- 이제, 이렇게 변환된 특성을 활용하여 다중 회귀 모델을 훈련해보자.\n",
        "- 훈련 세트를 기준으로 테스트 세트를 변환하는 습관을 들여보자!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHJOQRzsyrRf"
      },
      "source": [
        "## 3. 다중 회귀 모델 훈련하기\n",
        "- 다중 회귀 모델을 훈련하는 것은, 선형 회귀 모델을 훈련하는 것과 같다. 하지만, **여러 개의 특성**을 사용하여 선형 회귀를 수행한다는 점이 다르다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3UqQA8oybEL",
        "outputId": "e474017c-7873-42c8-d700-8286f218dba9"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lr = LinearRegression()\n",
        "lr.fit(train_poly, train_target)\n",
        "\n",
        "lr.score(train_poly, train_target)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9903183436982124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7M55dvDzCIh",
        "outputId": "d13b47f6-1f2e-4be8-f5a9-febf4506219a"
      },
      "source": [
        "#테스트 세트에 대한 점수도 같이 확인\n",
        "lr.score(test_poly, test_target)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9714559911594132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeJQdoSIzsNt"
      },
      "source": [
        "- 농어의 길이만 사용했을 때 있던 과소적합의 문제는 사라졌다.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "- 특성을 더 많이 사용하게 된다면?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PECZoywnzrW3",
        "outputId": "34fb6495-7c46-4f85-fec1-7f6ce528a0fe"
      },
      "source": [
        "poly = PolynomialFeatures(degree = 5, include_bias = False)\n",
        "poly.fit(train_input)\n",
        "train_poly = poly.transform(train_input)\n",
        "test_poly = poly.transform(test_input)\n",
        "\n",
        "train_poly.shape\n",
        "#만들어진 특성의 개수가 무려 55개나 된다."
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 55)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZXdeel50QL_",
        "outputId": "366a8f68-75a1-410f-e4c8-22efe3e1d42c"
      },
      "source": [
        "lr.fit(train_poly, train_target)\n",
        "lr.score(train_poly, train_target)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999999991096"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwvxu1QC0b5j",
        "outputId": "27fad95c-daf5-4bb5-850d-247a707f7e7a"
      },
      "source": [
        "#테스트 세트에 대한 결과는?\n",
        "lr.score(test_poly, test_target)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-144.40579242335605"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG3M5Zrv0j9Z"
      },
      "source": [
        "- 위와 같이, 특성의 개수를 늘리면 선형 모델은 아주 강력해져서 훈련 세트에 대해 거의 완벽한 학습이 가능해진다.\n",
        "- 하지만, 훈련 세트에 과대적합되기 때문에 테스트 세트에서는 적합되지 않아 음수가 나오게 된 것이다.\n",
        "- 또한, 사용된 샘플의 개수는 42개인데, 55개의 특성으로 훈련을 하게 된 모습이다.\n",
        "  - 42개의 참새를 맞추기 위해서 딱 한 번 새총을 쏴야 한다면, 참새 떼 중앙을 겨냥하여 가능한 맞출 가능성을 높여야 한다.\n",
        "  - 하지만 55번이나 쏠 수 있다면, 한 번에 하나씩 모든 참새를 맞출 수 있기 때문에 훈련 세트에서 점수가 높게 나오게 된 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbCA8P4F1QUo"
      },
      "source": [
        "## 4. 규제 (Regularization)\n",
        "- **규제**: 머신러닝 모델이 훈련 세트를 과도하게 학습하지 못하도록 훼방하는 것 (모델이 훈련 세트에 **과대적합 되지 않도록** 만드는 것)\n",
        "  - 선형 회귀 모델의 경우, 특성에 곱해지는 **계수(기울기)의 크기를 작게 만드는 것**이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqy9d2WW0iUm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}