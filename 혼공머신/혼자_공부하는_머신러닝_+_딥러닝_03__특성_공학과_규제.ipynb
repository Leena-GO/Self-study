{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "혼자_공부하는_머신러닝_+_딥러닝_03__특성_공학과_규제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSsd/XoBvktSkBv+iKYIdb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leena-GO/Self-study/blob/main/%ED%98%BC%EA%B3%B5%EB%A8%B8%EC%8B%A0/%ED%98%BC%EC%9E%90_%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%2B_%EB%94%A5%EB%9F%AC%EB%8B%9D_03__%ED%8A%B9%EC%84%B1_%EA%B3%B5%ED%95%99%EA%B3%BC_%EA%B7%9C%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_LOVpWVHAND"
      },
      "source": [
        "# 03-3 특성 공학과 규제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqBTmrN7HMcV"
      },
      "source": [
        "- 앞서 공부했던 *다항 회귀*에서, 훈련 세트보다 테스트 세트의 점수가 높은 **과소 적합**의 문제가 있었다.\n",
        "- 이를 해결하기 위해, **다중 회귀**를 사용해본다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4xHUD-FJtUl"
      },
      "source": [
        "## 1. 다중 회귀(Multiple Regression)\n",
        "- **다중회귀**: 여러 개의 특성을 사용한 선형 회귀, 특성이 많으면 선형모델은 강력한 성능을 발휘한다.\n",
        "  - 2개의 특성을 사용하면, 선형회귀는 *평면(3차원)*을 학습하게 된다.\n",
        "  - *타깃 = (a x 특성1) + (b x 특성2) + 절편* \n",
        "\n",
        "- 위 식과 같이, 기존의 특성을 사용하여 새로운 특성을 뽑아내는 작업을 **특성 공학**(Feature Engineering)이라고 한다.\n",
        "\n",
        "\n",
        "---\n",
        "- 특성이 3개로 늘어났기 때문에, numpy 대신 pandas DataFrame을 사용하여 데이터를 활용하도록 한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BskSNykWJwrq"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://bit.ly/perch_csv')\n",
        "perch_full = df.to_numpy() #DataFrame을 numpy 배열로 바꿔주는 메서드"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EVpxLH85LhJP",
        "outputId": "e3bfba58-95c8-4c89-b9be-3390f72e683a"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.4</td>\n",
              "      <td>2.11</td>\n",
              "      <td>1.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.7</td>\n",
              "      <td>3.53</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15.0</td>\n",
              "      <td>3.82</td>\n",
              "      <td>2.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.2</td>\n",
              "      <td>4.59</td>\n",
              "      <td>2.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.4</td>\n",
              "      <td>4.59</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>18.0</td>\n",
              "      <td>5.22</td>\n",
              "      <td>3.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>18.7</td>\n",
              "      <td>5.20</td>\n",
              "      <td>3.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>19.0</td>\n",
              "      <td>5.64</td>\n",
              "      <td>3.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>19.6</td>\n",
              "      <td>5.14</td>\n",
              "      <td>3.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20.0</td>\n",
              "      <td>5.08</td>\n",
              "      <td>2.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>21.0</td>\n",
              "      <td>5.69</td>\n",
              "      <td>3.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>21.0</td>\n",
              "      <td>5.92</td>\n",
              "      <td>3.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>21.0</td>\n",
              "      <td>5.69</td>\n",
              "      <td>3.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>21.3</td>\n",
              "      <td>6.38</td>\n",
              "      <td>3.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6.11</td>\n",
              "      <td>3.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>22.0</td>\n",
              "      <td>5.64</td>\n",
              "      <td>3.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6.11</td>\n",
              "      <td>3.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>22.0</td>\n",
              "      <td>5.88</td>\n",
              "      <td>3.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>22.0</td>\n",
              "      <td>5.52</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>22.5</td>\n",
              "      <td>5.86</td>\n",
              "      <td>3.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>22.5</td>\n",
              "      <td>6.79</td>\n",
              "      <td>3.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22.7</td>\n",
              "      <td>5.95</td>\n",
              "      <td>3.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23.0</td>\n",
              "      <td>5.22</td>\n",
              "      <td>3.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23.5</td>\n",
              "      <td>6.28</td>\n",
              "      <td>3.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24.0</td>\n",
              "      <td>7.29</td>\n",
              "      <td>3.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>24.0</td>\n",
              "      <td>6.38</td>\n",
              "      <td>3.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>24.6</td>\n",
              "      <td>6.73</td>\n",
              "      <td>4.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>25.0</td>\n",
              "      <td>6.44</td>\n",
              "      <td>3.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>25.6</td>\n",
              "      <td>6.56</td>\n",
              "      <td>4.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>26.5</td>\n",
              "      <td>7.17</td>\n",
              "      <td>4.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>27.3</td>\n",
              "      <td>8.32</td>\n",
              "      <td>5.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>27.5</td>\n",
              "      <td>7.17</td>\n",
              "      <td>4.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>27.5</td>\n",
              "      <td>7.05</td>\n",
              "      <td>4.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>27.5</td>\n",
              "      <td>7.28</td>\n",
              "      <td>4.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>28.0</td>\n",
              "      <td>7.82</td>\n",
              "      <td>4.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>28.7</td>\n",
              "      <td>7.59</td>\n",
              "      <td>4.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>30.0</td>\n",
              "      <td>7.62</td>\n",
              "      <td>4.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>32.8</td>\n",
              "      <td>10.03</td>\n",
              "      <td>6.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>34.5</td>\n",
              "      <td>10.26</td>\n",
              "      <td>6.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>35.0</td>\n",
              "      <td>11.49</td>\n",
              "      <td>7.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>36.5</td>\n",
              "      <td>10.88</td>\n",
              "      <td>6.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>36.0</td>\n",
              "      <td>10.61</td>\n",
              "      <td>6.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>37.0</td>\n",
              "      <td>10.84</td>\n",
              "      <td>6.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>37.0</td>\n",
              "      <td>10.57</td>\n",
              "      <td>6.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>39.0</td>\n",
              "      <td>11.14</td>\n",
              "      <td>7.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>39.0</td>\n",
              "      <td>11.14</td>\n",
              "      <td>6.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>39.0</td>\n",
              "      <td>12.43</td>\n",
              "      <td>7.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>40.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>7.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>40.0</td>\n",
              "      <td>11.73</td>\n",
              "      <td>7.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>40.0</td>\n",
              "      <td>12.38</td>\n",
              "      <td>7.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>40.0</td>\n",
              "      <td>11.14</td>\n",
              "      <td>6.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>42.0</td>\n",
              "      <td>12.80</td>\n",
              "      <td>6.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>43.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>7.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>43.0</td>\n",
              "      <td>12.51</td>\n",
              "      <td>7.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>43.5</td>\n",
              "      <td>12.60</td>\n",
              "      <td>8.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>44.0</td>\n",
              "      <td>12.49</td>\n",
              "      <td>7.60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    length   height   width\n",
              "0      8.4     2.11    1.41\n",
              "1     13.7     3.53    2.00\n",
              "2     15.0     3.82    2.43\n",
              "3     16.2     4.59    2.63\n",
              "4     17.4     4.59    2.94\n",
              "5     18.0     5.22    3.32\n",
              "6     18.7     5.20    3.12\n",
              "7     19.0     5.64    3.05\n",
              "8     19.6     5.14    3.04\n",
              "9     20.0     5.08    2.77\n",
              "10    21.0     5.69    3.56\n",
              "11    21.0     5.92    3.31\n",
              "12    21.0     5.69    3.67\n",
              "13    21.3     6.38    3.53\n",
              "14    22.0     6.11    3.41\n",
              "15    22.0     5.64    3.52\n",
              "16    22.0     6.11    3.52\n",
              "17    22.0     5.88    3.52\n",
              "18    22.0     5.52    4.00\n",
              "19    22.5     5.86    3.62\n",
              "20    22.5     6.79    3.62\n",
              "21    22.7     5.95    3.63\n",
              "22    23.0     5.22    3.63\n",
              "23    23.5     6.28    3.72\n",
              "24    24.0     7.29    3.72\n",
              "25    24.0     6.38    3.82\n",
              "26    24.6     6.73    4.17\n",
              "27    25.0     6.44    3.68\n",
              "28    25.6     6.56    4.24\n",
              "29    26.5     7.17    4.14\n",
              "30    27.3     8.32    5.14\n",
              "31    27.5     7.17    4.34\n",
              "32    27.5     7.05    4.34\n",
              "33    27.5     7.28    4.57\n",
              "34    28.0     7.82    4.20\n",
              "35    28.7     7.59    4.64\n",
              "36    30.0     7.62    4.77\n",
              "37    32.8    10.03    6.02\n",
              "38    34.5    10.26    6.39\n",
              "39    35.0    11.49    7.80\n",
              "40    36.5    10.88    6.86\n",
              "41    36.0    10.61    6.74\n",
              "42    37.0    10.84    6.26\n",
              "43    37.0    10.57    6.37\n",
              "44    39.0    11.14    7.49\n",
              "45    39.0    11.14    6.00\n",
              "46    39.0    12.43    7.35\n",
              "47    40.0    11.93    7.11\n",
              "48    40.0    11.73    7.22\n",
              "49    40.0    12.38    7.46\n",
              "50    40.0    11.14    6.63\n",
              "51    42.0    12.80    6.87\n",
              "52    43.0    11.93    7.28\n",
              "53    43.0    12.51    7.42\n",
              "54    43.5    12.60    8.14\n",
              "55    44.0    12.49    7.60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfv-gO72Lj4D",
        "outputId": "b4d0eda4-022b-4c16-c776-e3edfa0be2c7"
      },
      "source": [
        "perch_full"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 8.4 ,  2.11,  1.41],\n",
              "       [13.7 ,  3.53,  2.  ],\n",
              "       [15.  ,  3.82,  2.43],\n",
              "       [16.2 ,  4.59,  2.63],\n",
              "       [17.4 ,  4.59,  2.94],\n",
              "       [18.  ,  5.22,  3.32],\n",
              "       [18.7 ,  5.2 ,  3.12],\n",
              "       [19.  ,  5.64,  3.05],\n",
              "       [19.6 ,  5.14,  3.04],\n",
              "       [20.  ,  5.08,  2.77],\n",
              "       [21.  ,  5.69,  3.56],\n",
              "       [21.  ,  5.92,  3.31],\n",
              "       [21.  ,  5.69,  3.67],\n",
              "       [21.3 ,  6.38,  3.53],\n",
              "       [22.  ,  6.11,  3.41],\n",
              "       [22.  ,  5.64,  3.52],\n",
              "       [22.  ,  6.11,  3.52],\n",
              "       [22.  ,  5.88,  3.52],\n",
              "       [22.  ,  5.52,  4.  ],\n",
              "       [22.5 ,  5.86,  3.62],\n",
              "       [22.5 ,  6.79,  3.62],\n",
              "       [22.7 ,  5.95,  3.63],\n",
              "       [23.  ,  5.22,  3.63],\n",
              "       [23.5 ,  6.28,  3.72],\n",
              "       [24.  ,  7.29,  3.72],\n",
              "       [24.  ,  6.38,  3.82],\n",
              "       [24.6 ,  6.73,  4.17],\n",
              "       [25.  ,  6.44,  3.68],\n",
              "       [25.6 ,  6.56,  4.24],\n",
              "       [26.5 ,  7.17,  4.14],\n",
              "       [27.3 ,  8.32,  5.14],\n",
              "       [27.5 ,  7.17,  4.34],\n",
              "       [27.5 ,  7.05,  4.34],\n",
              "       [27.5 ,  7.28,  4.57],\n",
              "       [28.  ,  7.82,  4.2 ],\n",
              "       [28.7 ,  7.59,  4.64],\n",
              "       [30.  ,  7.62,  4.77],\n",
              "       [32.8 , 10.03,  6.02],\n",
              "       [34.5 , 10.26,  6.39],\n",
              "       [35.  , 11.49,  7.8 ],\n",
              "       [36.5 , 10.88,  6.86],\n",
              "       [36.  , 10.61,  6.74],\n",
              "       [37.  , 10.84,  6.26],\n",
              "       [37.  , 10.57,  6.37],\n",
              "       [39.  , 11.14,  7.49],\n",
              "       [39.  , 11.14,  6.  ],\n",
              "       [39.  , 12.43,  7.35],\n",
              "       [40.  , 11.93,  7.11],\n",
              "       [40.  , 11.73,  7.22],\n",
              "       [40.  , 12.38,  7.46],\n",
              "       [40.  , 11.14,  6.63],\n",
              "       [42.  , 12.8 ,  6.87],\n",
              "       [43.  , 11.93,  7.28],\n",
              "       [43.  , 12.51,  7.42],\n",
              "       [43.5 , 12.6 ,  8.14],\n",
              "       [44.  , 12.49,  7.6 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkKelE7yJwpm"
      },
      "source": [
        "#타깃 데이터 준비\n",
        "import numpy as np\n",
        "\n",
        "#농어의 특성을 활용하여 무게를 예측하는 작업이기 때문에, 타깃 데이터가 되는 무게만 가지고 온다.\n",
        "perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,\n",
        "       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,\n",
        "       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,\n",
        "       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,\n",
        "       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,\n",
        "       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,\n",
        "       1000.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKwbsrsaLsbj"
      },
      "source": [
        "#perch_full과 perch_weight을 훈련 세트와 테스트 세트로 나눠주기\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train_input, train_target, test_input, test_target = train_test_split(perch_full, perch_weight, random_state = 42)\n",
        "train_input, test_input, train_target, test_target = train_test_split(perch_full, perch_weight, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP7K8zGbx3Vq"
      },
      "source": [
        "- 정말 크게 깨달은 점: input 데이터와 target 데이터의 순서를 달리 하면, 문제가 생긴다ㅠㅠ\n",
        "  - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFGdZP1GwBHi",
        "outputId": "2ea564d3-af5c-4b77-b477-e0bf659e971d"
      },
      "source": [
        "train_input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19.6 ,  5.14,  3.04],\n",
              "       [22.  ,  5.88,  3.52],\n",
              "       [18.7 ,  5.2 ,  3.12],\n",
              "       [17.4 ,  4.59,  2.94],\n",
              "       [36.  , 10.61,  6.74],\n",
              "       [25.  ,  6.44,  3.68],\n",
              "       [40.  , 11.93,  7.11],\n",
              "       [39.  , 12.43,  7.35],\n",
              "       [43.  , 11.93,  7.28],\n",
              "       [22.  ,  5.64,  3.52],\n",
              "       [20.  ,  5.08,  2.77],\n",
              "       [22.  ,  6.11,  3.52],\n",
              "       [24.  ,  7.29,  3.72],\n",
              "       [27.5 ,  7.17,  4.34],\n",
              "       [43.  , 12.51,  7.42],\n",
              "       [40.  , 11.73,  7.22],\n",
              "       [24.  ,  6.38,  3.82],\n",
              "       [21.  ,  5.92,  3.31],\n",
              "       [27.5 ,  7.05,  4.34],\n",
              "       [40.  , 12.38,  7.46],\n",
              "       [32.8 , 10.03,  6.02],\n",
              "       [26.5 ,  7.17,  4.14],\n",
              "       [36.5 , 10.88,  6.86],\n",
              "       [13.7 ,  3.53,  2.  ],\n",
              "       [22.7 ,  5.95,  3.63],\n",
              "       [15.  ,  3.82,  2.43],\n",
              "       [37.  , 10.57,  6.37],\n",
              "       [35.  , 11.49,  7.8 ],\n",
              "       [28.7 ,  7.59,  4.64],\n",
              "       [23.5 ,  6.28,  3.72],\n",
              "       [39.  , 11.14,  6.  ],\n",
              "       [21.  ,  5.69,  3.56],\n",
              "       [23.  ,  5.22,  3.63],\n",
              "       [22.  ,  5.52,  4.  ],\n",
              "       [44.  , 12.49,  7.6 ],\n",
              "       [22.5 ,  6.79,  3.62],\n",
              "       [19.  ,  5.64,  3.05],\n",
              "       [37.  , 10.84,  6.26],\n",
              "       [22.  ,  6.11,  3.41],\n",
              "       [25.6 ,  6.56,  4.24],\n",
              "       [42.  , 12.8 ,  6.87],\n",
              "       [34.5 , 10.26,  6.39]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWmWTHUJwMnu",
        "outputId": "348d2406-39ea-48ae-a5d1-1145cf1ce374"
      },
      "source": [
        "train_target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 8.4 ,  2.11,  1.41],\n",
              "       [18.  ,  5.22,  3.32],\n",
              "       [27.5 ,  7.28,  4.57],\n",
              "       [21.3 ,  6.38,  3.53],\n",
              "       [22.5 ,  5.86,  3.62],\n",
              "       [40.  , 11.14,  6.63],\n",
              "       [30.  ,  7.62,  4.77],\n",
              "       [24.6 ,  6.73,  4.17],\n",
              "       [39.  , 11.14,  7.49],\n",
              "       [21.  ,  5.69,  3.67],\n",
              "       [43.5 , 12.6 ,  8.14],\n",
              "       [16.2 ,  4.59,  2.63],\n",
              "       [28.  ,  7.82,  4.2 ],\n",
              "       [27.3 ,  8.32,  5.14]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTblr3A5v_Sy",
        "outputId": "0f020e43-a005-456c-e0c8-eae88a11776a"
      },
      "source": [
        "test_input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  85.,  135.,   78.,   70.,  700.,  180.,  850.,  820., 1000.,\n",
              "        120.,   85.,  130.,  225.,  260., 1100.,  900.,  145.,  115.,\n",
              "        265., 1015.,  514.,  218.,  685.,   32.,  145.,   40.,  690.,\n",
              "        840.,  300.,  170.,  650.,  110.,  150.,  110., 1000.,  150.,\n",
              "         80.,  700.,  120.,  197., 1100.,  556.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtM0-jcMwON8",
        "outputId": "2df9e7ae-8bb8-4951-ce3c-6b4a4a6aec71"
      },
      "source": [
        "test_target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   5.9,  100. ,  250. ,  130. ,  130. ,  820. ,  320. ,  188. ,\n",
              "        900. ,  125. , 1000. ,   51.5,  250. ,  300. ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paCEKCJvyKpy"
      },
      "source": [
        "- test_input이 'perch_full' 데이터를 활용하여 input 데이터가 되어야 하는데, 순서가 바뀌어서 이런 문제가 발생하게 된 것..!!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "a5ymxLz5uiIz",
        "outputId": "2d160aa1-e26c-4b4e-9c18-e9abf09edb8d"
      },
      "source": [
        "test_poly = poly.transform(test_input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-a75818d90443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_poly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m         X = check_array(X, order='F', dtype=FLOAT_DTYPES,\n\u001b[0;32m-> 1546\u001b[0;31m                         accept_sparse=('csr', 'csc'))\n\u001b[0m\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[  85.  135.   78.   70.  700.  180.  850.  820. 1000.  120.   85.  130.\n  225.  260. 1100.  900.  145.  115.  265. 1015.  514.  218.  685.   32.\n  145.   40.  690.  840.  300.  170.  650.  110.  150.  110. 1000.  150.\n   80.  700.  120.  197. 1100.  556.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrc17rggL-xW"
      },
      "source": [
        "## 2. 사이킷런의 변환기\n",
        "- 사이킷런은 **특성을 만들**거나, **전처리**하기 위한 다양한 클래스를 제공하는데, 이러한 클래스를 **변환기**(transformer)라고 한다.\n",
        "  - 변환기 클래스는 모두 **fit()**, **transform()** 메서드를 제공한다.\n",
        "  - 앞서 배운 LinearRegression 같은 사이킷런 모델 클래스는 **추정기**(estimator)라고 한다.\n",
        "\n",
        "\n",
        "\n",
        "  - 이번 공부에서는 **PolynomialFeatures**클래스를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "810MkE2PGrLf",
        "outputId": "24c13db3-8c7c-473a-d1f5-fe0b958fa208"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly = PolynomialFeatures()\n",
        "\n",
        "#테스트로, 2개의 특성 2와 3으로 이루어진 샘플 하나를 적용해보자.\n",
        "poly.fit([[2,3]])\n",
        "poly.transform([[2,3]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2., 3., 4., 6., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ND1D2bvM-rK"
      },
      "source": [
        "- 변환기(transformer)는 타깃 데이터가 필요하지 않다.\n",
        "  - 예) k-최근접이웃 회귀에서는 **knr.fit(train_input, train_target)** 과 같이, 타깃 데이터를 넣어주었다.\n",
        "\n",
        "\n",
        "- 위에서 보다시피, 2개의 특성(원소)을 가진 샘플 [2,3]이 6개의 특성을 가진 샘플 [1,2,3,4,6,9]로, 특성이 많아졌다!\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "- PolynomialFeatures 클래스는 기본적으로 각 특성을 제곱한 항을 추가하고, 특성끼리 서로 곱한 항을 추가한다.\n",
        "\n",
        "\n",
        "\n",
        "- 위의 상황에서, 1은 왜 추가가 된 것일까?\n",
        "  - *무게 = (a x 길이) + (b x 높이) + (c x 두께) + (d x 1)*\n",
        "  - 선형 방정식의 절편은, 항상 값이 1인 특성과 곱해지는 계수로 볼 수 있다.\n",
        "  - 사이킷런의 선형 모델은 자동으로 절편을 추가하므로, 굳이 1을 필요로 하지 않는다.\n",
        "  - **include_bias = False**로 지정하여 특성을 변환해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh6cPyUbudX_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**PolynomialFeatures**: Generate polynomial and interaction features.\n",
        "\n",
        "  - Generate a new feature matrix consisting of all polynomial combinations\n",
        "of the features with degree less than or equal to the specified degree.\n",
        "    - For example, if an input sample is two dimensional and of the form\n",
        "[a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].\n",
        "\n",
        "- Parameters\n",
        "\n",
        "  - degree : integer\n",
        "      - The degree of the polynomial features. Default = 2.\n",
        "\n",
        "  - interaction_only : boolean, default = False\n",
        "      - If true, only interaction features are produced: features that are\n",
        "    products of at most degree distinct input features. (거듭제곱 항 제외)\n",
        "\n",
        "  - include_bias : boolean\n",
        "      - If True (default), then include a bias column, the feature in which\n",
        "    all polynomial powers are zero (i.e. a column of ones - acts as an\n",
        "    intercept term in a linear model).\n",
        "\n",
        "  - order : str in {'C', 'F'}, default 'C'\n",
        "      - Order of output array in the dense case. 'F' order is faster to\n",
        "    compute, but may slow down subsequent estimators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1yRCFAPM6HB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0135f5c4-fae8-42de-f6af-7f44a1a0e28e"
      },
      "source": [
        "poly = PolynomialFeatures(include_bias = False)\n",
        "\n",
        "poly.fit([[2,3]])\n",
        "poly.transform([[2,3]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 3., 4., 6., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EzqoWwWutge"
      },
      "source": [
        "- 이렇게, 절편을 위한 항이 제거되고, 특성의 제곱과 특성끼리 곱한 항만 추가가 되었다.\n",
        "- 이 방식으로 *train_input*에 적용해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETYSGiDkutSr",
        "outputId": "88348fb8-ac2e-4648-b215-58ffd0125e1e"
      },
      "source": [
        "poly = PolynomialFeatures(include_bias = False)\n",
        "\n",
        "poly.fit(train_input)\n",
        "train_poly = poly.transform(train_input)\n",
        "train_poly.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySO3p8fVvd-3",
        "outputId": "04aaf889-29cd-494d-ad12-1447cc43382e"
      },
      "source": [
        "#train_input의 총 len은 42개\n",
        "len(train_input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVztsg-KulmC",
        "outputId": "ac854bb5-f5e9-42bb-8887-5d4af6777b33"
      },
      "source": [
        "#위 9개 특성이 어떻게 만들어졌는지 확인하는 방법: get_feature_names()\n",
        "poly.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x0', 'x1', 'x2', 'x0^2', 'x0 x1', 'x0 x2', 'x1^2', 'x1 x2', 'x2^2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA9ANU5TzKr3",
        "outputId": "afb5003e-5aae-4bea-ac90-e9d4d52b1c08"
      },
      "source": [
        "#기존에 있던 3개의 특성을 가지고, 위의 방법으로 9개의 특성까지 만들어냈다.\n",
        "train_poly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  19.6   ,    5.14  ,    3.04  ,  384.16  ,  100.744 ,   59.584 ,\n",
              "          26.4196,   15.6256,    9.2416],\n",
              "       [  22.    ,    5.88  ,    3.52  ,  484.    ,  129.36  ,   77.44  ,\n",
              "          34.5744,   20.6976,   12.3904],\n",
              "       [  18.7   ,    5.2   ,    3.12  ,  349.69  ,   97.24  ,   58.344 ,\n",
              "          27.04  ,   16.224 ,    9.7344],\n",
              "       [  17.4   ,    4.59  ,    2.94  ,  302.76  ,   79.866 ,   51.156 ,\n",
              "          21.0681,   13.4946,    8.6436],\n",
              "       [  36.    ,   10.61  ,    6.74  , 1296.    ,  381.96  ,  242.64  ,\n",
              "         112.5721,   71.5114,   45.4276],\n",
              "       [  25.    ,    6.44  ,    3.68  ,  625.    ,  161.    ,   92.    ,\n",
              "          41.4736,   23.6992,   13.5424],\n",
              "       [  40.    ,   11.93  ,    7.11  , 1600.    ,  477.2   ,  284.4   ,\n",
              "         142.3249,   84.8223,   50.5521],\n",
              "       [  39.    ,   12.43  ,    7.35  , 1521.    ,  484.77  ,  286.65  ,\n",
              "         154.5049,   91.3605,   54.0225],\n",
              "       [  43.    ,   11.93  ,    7.28  , 1849.    ,  512.99  ,  313.04  ,\n",
              "         142.3249,   86.8504,   52.9984],\n",
              "       [  22.    ,    5.64  ,    3.52  ,  484.    ,  124.08  ,   77.44  ,\n",
              "          31.8096,   19.8528,   12.3904],\n",
              "       [  20.    ,    5.08  ,    2.77  ,  400.    ,  101.6   ,   55.4   ,\n",
              "          25.8064,   14.0716,    7.6729],\n",
              "       [  22.    ,    6.11  ,    3.52  ,  484.    ,  134.42  ,   77.44  ,\n",
              "          37.3321,   21.5072,   12.3904],\n",
              "       [  24.    ,    7.29  ,    3.72  ,  576.    ,  174.96  ,   89.28  ,\n",
              "          53.1441,   27.1188,   13.8384],\n",
              "       [  27.5   ,    7.17  ,    4.34  ,  756.25  ,  197.175 ,  119.35  ,\n",
              "          51.4089,   31.1178,   18.8356],\n",
              "       [  43.    ,   12.51  ,    7.42  , 1849.    ,  537.93  ,  319.06  ,\n",
              "         156.5001,   92.8242,   55.0564],\n",
              "       [  40.    ,   11.73  ,    7.22  , 1600.    ,  469.2   ,  288.8   ,\n",
              "         137.5929,   84.6906,   52.1284],\n",
              "       [  24.    ,    6.38  ,    3.82  ,  576.    ,  153.12  ,   91.68  ,\n",
              "          40.7044,   24.3716,   14.5924],\n",
              "       [  21.    ,    5.92  ,    3.31  ,  441.    ,  124.32  ,   69.51  ,\n",
              "          35.0464,   19.5952,   10.9561],\n",
              "       [  27.5   ,    7.05  ,    4.34  ,  756.25  ,  193.875 ,  119.35  ,\n",
              "          49.7025,   30.597 ,   18.8356],\n",
              "       [  40.    ,   12.38  ,    7.46  , 1600.    ,  495.2   ,  298.4   ,\n",
              "         153.2644,   92.3548,   55.6516],\n",
              "       [  32.8   ,   10.03  ,    6.02  , 1075.84  ,  328.984 ,  197.456 ,\n",
              "         100.6009,   60.3806,   36.2404],\n",
              "       [  26.5   ,    7.17  ,    4.14  ,  702.25  ,  190.005 ,  109.71  ,\n",
              "          51.4089,   29.6838,   17.1396],\n",
              "       [  36.5   ,   10.88  ,    6.86  , 1332.25  ,  397.12  ,  250.39  ,\n",
              "         118.3744,   74.6368,   47.0596],\n",
              "       [  13.7   ,    3.53  ,    2.    ,  187.69  ,   48.361 ,   27.4   ,\n",
              "          12.4609,    7.06  ,    4.    ],\n",
              "       [  22.7   ,    5.95  ,    3.63  ,  515.29  ,  135.065 ,   82.401 ,\n",
              "          35.4025,   21.5985,   13.1769],\n",
              "       [  15.    ,    3.82  ,    2.43  ,  225.    ,   57.3   ,   36.45  ,\n",
              "          14.5924,    9.2826,    5.9049],\n",
              "       [  37.    ,   10.57  ,    6.37  , 1369.    ,  391.09  ,  235.69  ,\n",
              "         111.7249,   67.3309,   40.5769],\n",
              "       [  35.    ,   11.49  ,    7.8   , 1225.    ,  402.15  ,  273.    ,\n",
              "         132.0201,   89.622 ,   60.84  ],\n",
              "       [  28.7   ,    7.59  ,    4.64  ,  823.69  ,  217.833 ,  133.168 ,\n",
              "          57.6081,   35.2176,   21.5296],\n",
              "       [  23.5   ,    6.28  ,    3.72  ,  552.25  ,  147.58  ,   87.42  ,\n",
              "          39.4384,   23.3616,   13.8384],\n",
              "       [  39.    ,   11.14  ,    6.    , 1521.    ,  434.46  ,  234.    ,\n",
              "         124.0996,   66.84  ,   36.    ],\n",
              "       [  21.    ,    5.69  ,    3.56  ,  441.    ,  119.49  ,   74.76  ,\n",
              "          32.3761,   20.2564,   12.6736],\n",
              "       [  23.    ,    5.22  ,    3.63  ,  529.    ,  120.06  ,   83.49  ,\n",
              "          27.2484,   18.9486,   13.1769],\n",
              "       [  22.    ,    5.52  ,    4.    ,  484.    ,  121.44  ,   88.    ,\n",
              "          30.4704,   22.08  ,   16.    ],\n",
              "       [  44.    ,   12.49  ,    7.6   , 1936.    ,  549.56  ,  334.4   ,\n",
              "         156.0001,   94.924 ,   57.76  ],\n",
              "       [  22.5   ,    6.79  ,    3.62  ,  506.25  ,  152.775 ,   81.45  ,\n",
              "          46.1041,   24.5798,   13.1044],\n",
              "       [  19.    ,    5.64  ,    3.05  ,  361.    ,  107.16  ,   57.95  ,\n",
              "          31.8096,   17.202 ,    9.3025],\n",
              "       [  37.    ,   10.84  ,    6.26  , 1369.    ,  401.08  ,  231.62  ,\n",
              "         117.5056,   67.8584,   39.1876],\n",
              "       [  22.    ,    6.11  ,    3.41  ,  484.    ,  134.42  ,   75.02  ,\n",
              "          37.3321,   20.8351,   11.6281],\n",
              "       [  25.6   ,    6.56  ,    4.24  ,  655.36  ,  167.936 ,  108.544 ,\n",
              "          43.0336,   27.8144,   17.9776],\n",
              "       [  42.    ,   12.8   ,    6.87  , 1764.    ,  537.6   ,  288.54  ,\n",
              "         163.84  ,   87.936 ,   47.1969],\n",
              "       [  34.5   ,   10.26  ,    6.39  , 1190.25  ,  353.97  ,  220.455 ,\n",
              "         105.2676,   65.5614,   40.8321]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yB64BH6vsMy"
      },
      "source": [
        "#테스트 세트 변환하기\n",
        "test_poly = poly.transform(test_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMzbyDs7ycTQ"
      },
      "source": [
        "- 이제, 이렇게 변환된 특성을 활용하여 다중 회귀 모델을 훈련해보자.\n",
        "- 훈련 세트를 기준으로 테스트 세트를 변환하는 습관을 들여보자!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHJOQRzsyrRf"
      },
      "source": [
        "## 3. 다중 회귀 모델 훈련하기\n",
        "- 다중 회귀 모델을 훈련하는 것은, 선형 회귀 모델을 훈련하는 것과 같다. 하지만, **여러 개의 특성**을 사용하여 선형 회귀를 수행한다는 점이 다르다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3UqQA8oybEL",
        "outputId": "8c9ec5ef-71fe-45d0-8fff-808bacdd5ae5"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lr = LinearRegression()\n",
        "lr.fit(train_poly, train_target)\n",
        "\n",
        "lr.score(train_poly, train_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9903183436982124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7M55dvDzCIh",
        "outputId": "c6b6daaa-23e8-459a-d65d-811488729027"
      },
      "source": [
        "#테스트 세트에 대한 점수도 같이 확인\n",
        "lr.score(test_poly, test_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9714559911594132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeJQdoSIzsNt"
      },
      "source": [
        "- 농어의 길이만 사용했을 때 있던 과소적합의 문제는 사라졌다.\n",
        "\n",
        "- 특성을 더 많이 사용하게 된다면?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PECZoywnzrW3",
        "outputId": "0397f878-5ef4-4ace-f713-8c40b06c61e1"
      },
      "source": [
        "poly = PolynomialFeatures(degree = 5, include_bias = False)\n",
        "poly.fit(train_input)\n",
        "train_poly = poly.transform(train_input)\n",
        "test_poly = poly.transform(test_input)\n",
        "\n",
        "train_poly.shape\n",
        "#만들어진 특성의 개수가 무려 55개나 된다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 55)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZXdeel50QL_",
        "outputId": "ccd9f387-cf50-4570-ab1f-8e7035c03fb0"
      },
      "source": [
        "lr.fit(train_poly, train_target)\n",
        "lr.score(train_poly, train_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999999991096"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwvxu1QC0b5j",
        "outputId": "eb5da187-7d5e-44ce-f52c-435e4a44da54"
      },
      "source": [
        "#테스트 세트에 대한 결과는?\n",
        "lr.score(test_poly, test_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-144.40579242335605"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG3M5Zrv0j9Z"
      },
      "source": [
        "- 위와 같이, 특성의 개수를 늘리면 선형 모델은 아주 강력해져서 훈련 세트에 대해 거의 완벽한 학습이 가능해진다.\n",
        "- 하지만, 훈련 세트에 과대적합되기 때문에 테스트 세트에서는 적합되지 않아 음수가 나오게 된 것이다.\n",
        "- 또한, 사용된 샘플의 개수는 42개인데, 55개의 특성으로 훈련을 하게 된 모습이다.\n",
        "  - 42개의 참새를 맞추기 위해서 딱 한 번 새총을 쏴야 한다면, 참새 떼 중앙을 겨냥하여 가능한 맞출 가능성을 높여야 한다.\n",
        "  - 하지만 55번이나 쏠 수 있다면, 한 번에 하나씩 모든 참새를 맞출 수 있기 때문에 훈련 세트에서 점수가 높게 나오게 된 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbCA8P4F1QUo"
      },
      "source": [
        "## 4. 규제 (Regularization)\n",
        "- **규제**: 머신러닝 모델이 훈련 세트를 과도하게 학습하지 못하도록 훼방하는 것 (모델이 훈련 세트에 **과대적합 되지 않도록** 만드는 것)\n",
        "  - 선형 회귀 모델의 경우, 특성에 곱해지는 **계수(기울기)의 크기를 작게 만드는 것**이다.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "- 55개의 특성으로 훈련한 선형 회귀 모델의 계수를 규제하여 훈련 세트의 점수를 낮추고 대신 테스트 세트의 점수를 높여보자.\n",
        "\n",
        "- **특성의 스케일**\n",
        "  - 특성의 스케일이 정규화되지 않으면 여기에 곱해지는 계수 값도 차이 나게 된다. (2장 참고)\n",
        "  - 선형 회귀 모델에 규제를 적용할 때 계수 값의 크기가 서로 많이 다르면 공정하게 제어되지 않는다.\n",
        "  - 따라서, **규제 적용 전에 정규화 작업**을 진행해주어야 한다.\n",
        "\n",
        "\n",
        "\n",
        "  - 2장에서는 평균과 표준편차를 직접 구해 특성을 표준점수로 바꾸었지만, 이번에는 **StandardScaler** 클래스를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqy9d2WW0iUm"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "ss.fit(train_poly) #PolynomialFeatures 클래스로 만든 train_poly(훈련세트)로 이 객체 학습\n",
        "\n",
        "train_scaled = ss.transform(train_poly)\n",
        "test_scaled = ss.transform(test_poly)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2olDywqeioLW",
        "outputId": "387af453-a9c1-4223-a0ab-3eb3ee007532"
      },
      "source": [
        "train_poly.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 55)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z1EaiERjZsz"
      },
      "source": [
        "- 선형 회귀 모델에 규제를 추가한 모델을 **릿지**(ridge)와 **라쏘**(lasso)라고 한다.\n",
        "  - **릿지**: 계수를 곱한 값을 기준으로 규제를 적용\n",
        "  - **라쏘**: 계수의 절댓값을 기준으로 규제를 적용, 계수의 크기를 0으로 만들 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsvE_Uipjurh"
      },
      "source": [
        "## 5. 릿지 회귀\n",
        "- 릿지와 라쏘 모두 sklearn.linear_model 패키지 안에 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u93jLE04izgL",
        "outputId": "865e41ba-1b8a-4fa4-be7c-e64107193e34"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "ridge = Ridge()\n",
        "ridge.fit(train_scaled, train_target)\n",
        "ridge.score(train_scaled, train_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9896101671037343"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP8SDO1Cnj9U"
      },
      "source": [
        "- 선형 회귀에서 나왔던 점수(0.9999999999991096)보다 조금 낮은 점수가 나왔다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIJVPRNvj_Vd",
        "outputId": "0a9de8ac-b915-46ab-d3cf-f4ac843ba4b9"
      },
      "source": [
        "#test set 점수 확인\n",
        "ridge.score(test_scaled, test_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9790693977615398"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l11qJ8OgqDs_"
      },
      "source": [
        "- 정규화가 되지 않았던 상태의 점수 (-144.40579242335605)에 비해, 정상화가 된 모습을 볼 수 있다.\n",
        "\n",
        "\n",
        "---\n",
        "- 릿지와 랏쏘 모델을 사용할 때, **alpha 매개변수**를 사용함으로써 규제의 강도를 임의로 조절할 수 있다.\n",
        "\n",
        "| alpha 값이 큰 경우 |alpha 값이 작은 경우   |\n",
        "|:-:|:-:|\n",
        "|규제강도가 세다 | 규제강도가 약하다  |\n",
        "|계수 값이 줄어듦|계수 값이 커짐|\n",
        "|과소적합 유도|과대적합 가능성 커짐|\n",
        "\n",
        "\n",
        "- **하이퍼파라미터**: 머신러닝 알고리즘이 학습하지 않는 파라미터, 사람이 사전에 지정해주어야 한다.\n",
        "  - ex) alpha 파라미터\n",
        "    - 적절한 alpha 값 찾는 방법: alpha 값에 대한 R²을 그려보는 것이다.\n",
        "   - 훈련 세트와 테스트 세트의 점수가 가장 가까운 지점이 최적의 alpha 값이 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgyVZ-7-p97e"
      },
      "source": [
        "#alpha값을 바꿀 때마다 score() 메서드의 결과를 저장할 리스트를 만든다.\n",
        "import matplotlib.pyplot as plt \n",
        "train_score = []\n",
        "test_score = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmb2wnF8twEF"
      },
      "source": [
        "alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "for alpha in alpha_list:\n",
        "  #릿지 모델 만들기\n",
        "  ridge = Ridge(alpha = alpha)\n",
        "  \n",
        "  #릿지 모델 훈련\n",
        "  ridge.fit(train_scaled, train_target)\n",
        "\n",
        "  #훈련 점수와 테스트 점수 저장\n",
        "  train_score.append(ridge.score(train_scaled, train_target))\n",
        "  test_score.append(ridge.score(test_scaled, test_target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJpFd5e40fT4"
      },
      "source": [
        "- alpha 값을 0.001부터 10배씩 늘렸기 때문에, alpha_list에 있는 6개의 값을 동일한 간격으로 나타내기 위해 로그 함수로 바꾸어 지수로 표현한다.\n",
        "  - ex) 0.001 → -3 / 0.01 → -2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "bqSsYOZF0Zp4",
        "outputId": "c31ffbff-2ea1-4034-93c3-6744ac8c8293"
      },
      "source": [
        "plt.plot(np.log10(alpha_list), train_score) #파랑색 그래프\n",
        "plt.plot(np.log10(alpha_list), test_score) #주황색 그래프\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrfCXUiM1CTz",
        "outputId": "11f4de6a-8138-4e8b-c8ae-4059e5650598"
      },
      "source": [
        "print(train_score)\n",
        "print('\\n')\n",
        "print(test_score)\n",
        "print('\\n')\n",
        "\n",
        "score_zip_1 = zip(train_score, test_score)\n",
        "difference1 = []\n",
        "\n",
        "for train_score_1, test_score_1 in score_zip_1:\n",
        "  score = (train_score_1 - test_score_1)\n",
        "  difference1.append(score)\n",
        "\n",
        "print(difference)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.9924957354689654, 0.9922988130765112, 0.9902080238600285, 0.9898116789062786, 0.9887624603020235, 0.9078618674946646]\n",
            "\n",
            "\n",
            "[0.9731817502723494, 0.9761545611184548, 0.9824382983968606, 0.9801844137326112, 0.9830309645308443, 0.9090772073024512]\n",
            "\n",
            "\n",
            "[0.01931398519661598, 0.016144251958056466, 0.007769725463167898, 0.00962726517366741, 0.0057314957711792625, -0.0012153398077866528]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC9vij-I1Xut"
      },
      "source": [
        "- -3일 때: 훈련 세트와 테스트 세트의 점수 차이가 아주 큼 / *과대적합*\n",
        "\n",
        "- 2일 때: 훈련 세트와 테스트 세트의 점수가 모두 낮아짐 / *과소적합*\n",
        "\n",
        "- -1일 때: 두 그래프의 차이가 제일 낮아지는 경우\n",
        "  - log함수를 사용했기 때문에, logㅈ -3일 때: 훈련 세트와 테스트 세트의 점수 차이가 아주 큼 / *과대적합*\n",
        "\n",
        "  - 2일 때: 훈련 세트와 테스트 세트의 점수가 모두 낮아짐 / *과소적합*\n",
        "\n",
        "  - -1일 때: 두 그래프의 차이가 제일 낮아지는 경우\n",
        "    - log함수를 사용했기 때문에, 10^-1 = 0.1 인 alpha 값이 최적."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Br07h7D07Eo",
        "outputId": "962a2a8a-d397-4dde-ac27-555c7526eae4"
      },
      "source": [
        "ridge = Ridge(alpha = 0.1)\n",
        "ridge.fit(train_scaled, train_target)\n",
        "\n",
        "\n",
        "print(ridge.score(train_scaled, train_target))\n",
        "print(ridge.score(test_scaled, test_target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9903815817570366\n",
            "0.9827976465386927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOBUr7PQ2usk"
      },
      "source": [
        "## 6. 라쏘 회귀\n",
        "- 라쏘는 릿지와 달리 **계수 값**을 **0**으로 만들 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ag59SN62o1S",
        "outputId": "c0db45b0-ad25-4454-a080-e1fe2ad7caad"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "lasso = Lasso()\n",
        "lasso.fit(train_scaled, train_target)\n",
        "lasso.score(train_scaled, train_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9897898972080961"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KDXIdtb3Ed2"
      },
      "source": [
        "- 라쏘에서도 역시, 선형 회귀에서 나왔던 점수(0.9999999999991096)보다 조금 낮은 점수가 나왔다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZSHw8z42_55",
        "outputId": "76de3f61-432e-450e-a9d5-6726badeb05c"
      },
      "source": [
        "lasso.score(test_scaled, test_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9800593698421883"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVMZEX4C3R6O"
      },
      "source": [
        "- 라쏘 모델도 alpha 매개변수로 규제의 강도를 조절할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUCBbuSx3MqG",
        "outputId": "fe9f20dd-9bb5-4046-8741-25d5baba4070"
      },
      "source": [
        "train_score = []\n",
        "test_score = []\n",
        "\n",
        "alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "for alpha in alpha_list:\n",
        "  \n",
        "  #라쏘 모델 만들기\n",
        "  lasso = Lasso(alpha = alpha, max_iter = 10000)\n",
        "\n",
        "  #라쏘 모델 훈련\n",
        "  lasso.fit(train_scaled, train_target)\n",
        "\n",
        "  #훈련 점수와 테스트 점수 저장\n",
        "  train_score.append(lasso.score(train_scaled, train_target))\n",
        "  test_score.append(lasso.score(test_scaled, test_target))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18778.697957792876, tolerance: 518.2793833333334\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12972.821345404844, tolerance: 518.2793833333334\n",
            "  positive)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZn2YesW397Y"
      },
      "source": [
        "- 라쏘 모델을 훈련할 때, **ConvergenceWarning**이란 경고가 발생한다.\n",
        "- 라쏘 모델은 최적 계수를 찾기 위해 반복적인 계산을 수행하는데, 지정한 반복 횟수가 부족할 때 이런 경고가 발생한다.\n",
        "- 이 문제를 해결하기 위해 **max_iter** 매개변수의 값을 지정해준 것이다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "wV776Xkx32Ux",
        "outputId": "7196451b-6d36-4b49-bfdf-cffea7dd593b"
      },
      "source": [
        "plt.plot(np.log10(alpha_list), train_score) \n",
        "plt.plot(np.log10(alpha_list), test_score)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aM7FuTm4pZp",
        "outputId": "7977b16f-2a6d-4817-bdb0-30e65f4798d2"
      },
      "source": [
        "print(train_score)\n",
        "print('\\n')\n",
        "print(test_score)\n",
        "\n",
        "\n",
        "#train_score과 test_score의 점수차 계산하기\n",
        "score_zip = zip(train_score, test_score)\n",
        "difference = []\n",
        "for train_score_i, test_score_i in score_zip:\n",
        "  difference.append(train_score_i - test_score_i)\n",
        "\n",
        "print('\\n')\n",
        "print(difference)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.9924957354689654, 0.9922988130765112, 0.9902080238600285, 0.9898116789062786, 0.9887624603020235, 0.9078618674946646]\n",
            "\n",
            "\n",
            "[0.9731817502723494, 0.9761545611184548, 0.9824382983968606, 0.9801844137326112, 0.9830309645308443, 0.9090772073024512]\n",
            "\n",
            "\n",
            "[0.01931398519661598, 0.016144251958056466, 0.007769725463167898, 0.00962726517366741, 0.0057314957711792625, -0.0012153398077866528]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re93H1nC96ql"
      },
      "source": [
        "- 여기서는 10¹ = 10 인 1이 alpha 값이 최적이라고 볼 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7xXvV4D44fZ",
        "outputId": "b340ceb5-20b2-4dbb-ae6b-8513735f984c"
      },
      "source": [
        "lasso = Lasso(alpha = 10)\n",
        "lasso.fit(train_scaled, train_target)\n",
        "print(lasso.score(train_scaled, train_target))\n",
        "print(lasso.score(test_scaled, test_target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9888067471131867\n",
            "0.9824470598706695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tav_csmJ-QSt",
        "outputId": "98cb3922-2799-4619-8055-2a9471819b73"
      },
      "source": [
        "#라쏘 모델 계수 중, 계수 값이 0인 항목들의 개수\n",
        "np.sum(lasso.coef_ == 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_xyKN3kAD4l"
      },
      "source": [
        "- 계수 값이 0인 항목들의 개수가 40개인 것으로 보아, 라쏘 모델이 사용한 특성은 15개밖에 되지 않는다는 것을 알 수 있다.\n",
        "- 라쏘 모델은 이렇게 **유용한 특성을 골라내는 용도**로 사용할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv9JgRarEv0N",
        "outputId": "c6bbefde-b7d9-4efc-8fe6-3426cb9fc12f"
      },
      "source": [
        "poly_test = PolynomialFeatures(include_bias = True)\n",
        "poly_test.fit([[2,3]])\n",
        "poly_test.transform([[2,3]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2., 3., 4., 6., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}