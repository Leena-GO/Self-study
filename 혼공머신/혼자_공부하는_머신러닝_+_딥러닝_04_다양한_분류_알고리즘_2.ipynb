{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "혼자_공부하는_머신러닝_+_딥러닝_04_다양한_분류_알고리즘-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQHRlnGwV5tZrKSCFqU/+7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leena-GO/Self-study/blob/main/%ED%98%BC%EA%B3%B5%EB%A8%B8%EC%8B%A0/%ED%98%BC%EC%9E%90_%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%2B_%EB%94%A5%EB%9F%AC%EB%8B%9D_04_%EB%8B%A4%EC%96%91%ED%95%9C_%EB%B6%84%EB%A5%98_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkwY-88JKYM7"
      },
      "source": [
        "# 04-2 확률적 경사 하강법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEn-GcqqK48o"
      },
      "source": [
        "## 1. 점진적인 학습\n",
        "- 훈련 데이터가 한 번에 준비되지 않고 조금씩 전달이 된다면, 모델을 훈련시키는데 어려움이 생길 수 있다.\n",
        "- 이전에 훈련한 모델을 버리지 않고도 새로운 데이터에 대해 조금씩 훈련을 할 수 있는 방법을 **점진적 학습(온라인 학습)**이라고 한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw_Zr4zInDEb"
      },
      "source": [
        "### 1) 확률적 경사 하강법\n",
        "- 대표적인 점진적 학습 알고리즘은 **확률적 경사 하강법**(Stochastic Gradient Desent)이라고 한다.\n",
        "  -  *확률적* == *무작위하게, 랜덤하게*\n",
        "    - 훈련 세트를 사용하여 모델을 훈련하므로, 경사하강법도 훈련 세트를 사용해서 가장 가파른 길을 찾게 된다.\n",
        "    - 전체 샘플을 사용하지 않고 딱 하나의 샘플을 훈련 세트에서 랜덤하게 골라서 가장 가파른 길을 찾는다.\n",
        "  - *경사 == 기울기*\n",
        "  - *하강법 == 내려가는 방법*\n",
        "    - 가장 가파른 경사를 따라, 원하는 지점에 도달하는 것이 목표\n",
        "    - 하지만 조금씩 내려오는 것이 중요하다.\n",
        "    - 이렇게 내려오는 과정이 경사 하강법 모델을 훈련하는 것이다.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "- 정리하자면..\n",
        "  - 훈련 세트에서 랜덤하게 하나의 샘플을 선택해서, 가파른 경사를 조금 내려간다.\n",
        "  - 그다음 훈련 세트에서 랜덤하게 또 다른 샘플을 하나 선택하여 경사를 조금 내려간다.\n",
        "  - 이렇게 전체 샘플을 모두 사용할 때까지 계속 진행한다.\n",
        "  - 만약 경사를 다 내려가지 못했다면, 훈련 세트에 모든 샘플을 채워넣고, 경사를 처음부터 다시 내려가는데, 만족할만한 위치에 도달할 때까지 계속 내려간다.\n",
        "\n",
        "  - 확률적 경사 하강법에서 훈련 세트를 (한 번) 모두 사용하는 과정을 **에포크**(epoch)라고 한다.\n",
        "    - 일반적으로 경사 하강법은 수십, 수백 번 이상의 에포크를 수행한다. \n",
        "\n",
        "---\n",
        "\n",
        "- **미니배치 경사 하강법** (Minibatch gradient descent): 무작위로 몇 개의 샘플을 선택하여 경사를 내려가는 방법\n",
        "- **배치 경사 하강법**(Batch gradient descent): 극단적으로 한 번 경사로를 따라 이동하기 위해 전체 샘플을 사용하는 방법\n",
        "  - 전체 데이터를 사용하므로 가장 안정적인 방법\n",
        "  - 그렇지만 그만큼 컴퓨터 자원을 많이 사용하게 되고, 데이터가 너무 많아 한 번에 전체 데이터를 모두 읽지 못할수도 있다.\n",
        "\n",
        "---\n",
        "\n",
        "- 확률적 경사 하강법은 train set를 이용하여 최적의 장소로 조금씩 이동하는 알고리즘이다.\n",
        "- train data가 모두 준비되어 있지 않아도 학습을 매일 이어나갈 수 있다,\n",
        "- **신경망 모델**이 확률적 경사 하강법이나 미니배치 경사 하강법을 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JCPA9Elo1uZ"
      },
      "source": [
        "### 2) 손실 함수 (Loss function)\n",
        "- 어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지 측정하는 기준\n",
        "- 손실함수의 값이 작을수록 좋은 것이나, 어떤 값이 최솟값인지 알 수 없다.\n",
        "- 가능한 많이 찾아보고 만족할만한 수준이라면 산을 다 내려왔다고 평가.\n",
        "- 다행히 많은 문제에 필요한 손실 함수는 이미 정의되어있다.\n",
        "\n",
        "  - cf) 손실함수 ≒ 비용함수\n",
        "\n",
        "|손실함수|비용함수|\n",
        "|:-:|:-:|\n",
        "|샘플 하나에 대한 손실 정의|훈련 세트에 있는 모든 샘플에 대한 손실 함수의 합|\n",
        "\n",
        "---\n",
        "\n",
        "- 만약 예측의 정확도를 손실 함수로 사용하게 될 경우, 4개의 샘플만이 존재할 때 가능한 정확도는 *0, 0.25, 0.5, 0.75, 1* 총 5가지뿐이다.\n",
        "  - 이렇게 듬성듬성하다면 경사 하강법을 사용할 수 없다.\n",
        "  - 달리 말하자면, 연속적이어야 경사 하강법을 사용할 수 있는 것이다!\n",
        "\n",
        "- 연속적인 손실 함수를 만들기 위해, **로지스틱 회귀 모델**이 확률을 출력했을 때처럼 0~1 사이의 값을 설정하도록 해야한다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W43T6hP4Hbr"
      },
      "source": [
        "### 3) 로지스틱 손실 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IPAC-aH4MVo"
      },
      "source": [
        "- 아래와 같은 상황이라고 가정을 해보자.\n",
        "\n",
        "|예측|정답(target)|샘플의 예측확률|\n",
        "|:-:|:-:|:-:|\n",
        "|1|1|0.9|\n",
        "|0|1|0.3|\n",
        "|0|0|0.2|\n",
        "|1|0|0.8|\n",
        "\n",
        "- 첫 번째 샘플의 예측은 0.9이므로, 양성 클래스의 타깃인 1과 곱한 다음 음수로 바꿀 수 있다.\n",
        "  - 0.9 x 1 → -0.9\n",
        "\n",
        "- 두 번째 샘플의 예측은 0.3이다. 타깃이 양성 클래스인데, 거리가 멀다.\n",
        "  - 0.3 x 1 → -0.3\n",
        "  - 첫 번째 샘플보다 높은 손실이 된다!\n",
        "\n",
        "- 세 번째 샘플의 예측은 0.2이나, 타깃인 음성 클래스를 곱해주면 값이 0이 된다.\n",
        "- 이를 방지하기 위해, 양성 클래스에 대한 예측으로 변경하여 값을 추출한다.\n",
        "  - 0.2(음성) → 0.8(양성)\n",
        "  - 0 → 1\n",
        "  - 1 x 0.8 → -0.8\n",
        "\n",
        "---\n",
        "\n",
        "- 이런 식으로 정리를 해보자면\n",
        "\n",
        "|예측|정답(target)|샘플의 예측확률|손실|손실 정도|\n",
        "|:-:|:-:|:-:|:-:|:-:|\n",
        "|1|1|0.9|-0.9|낮은 손실|\n",
        "|0|1|0.3|-0.3|높은 손실|\n",
        "|0|0|0.2|-0.8|낮은 손실|\n",
        "|1|0|0.8|-0.2|높은 손실|\n",
        "\n",
        "\n",
        "- 예측 확률을 사용하여 이런 방식으로 계산을 한다면, 연속적인 손실 함수를 얻을 수 있다.\n",
        "- 여기에서 로그 함수를 더 적용한다면, 최종 손실값은 양수가 되고 이해를 하기 쉬워진다.\n",
        "- 또한 로그 함수는 0에 가까울수록 아주 큰 음수가 되기 때문에, 손실을 아주 크게 만들어 모델에 큰 영향을 미치게 된다.\n",
        "\n",
        "---\n",
        "\n",
        "- 위 손실함수를 **로지스틱 손실 함수**(Logistic loss function) 또는 **이진 크로스엔트로피 손실 함수**(Binary cross-entropy loss function)이라고 한다.\n",
        "\n",
        "![img.png](https://gombru.github.io/assets/cross_entropy_loss/intro.png)\n",
        "\n",
        "- 다중 분류에서 사용하는 손실 함수는 **크로스엔트로피 손실 함수**(Cross-entropy loss function)이라고 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hjfQ6Uf-1CE"
      },
      "source": [
        "## 2. SGDClassifier\n",
        "- 확률적 경사 하강법을 사용한 분류 모델을 만들어보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrWE84hseD6i"
      },
      "source": [
        "import pandas as pd\n",
        "fish = pd.read_csv('https://bit.ly/fish_csv')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cng2e6SJ_NeH",
        "outputId": "c98bfb6c-cadb-48bd-8374-bcc354d17b98"
      },
      "source": [
        "fish.columns"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Species', 'Weight', 'Length', 'Diagonal', 'Height', 'Width'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwqfKzjG_All"
      },
      "source": [
        "#Species 열은 타깃 데이터로 설정\n",
        "fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()\n",
        "fish_target = fish['Species'].to_numpy()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyAtb_SB_VGU"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state = 42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkUmMolx_WTc"
      },
      "source": [
        "#훈련 세트와 테스트 세트의 특성을 표준화 전처리해준다.\n",
        "# 꼭 훈련 세트에서 학습한 통계값으로 테스트 세트를 변환해준다!\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "ss.fit(train_input)\n",
        "train_scaled = ss.transform(train_input)\n",
        "test_scaled = ss.transform(test_input)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgoyZ6ltACMv"
      },
      "source": [
        "- 표준화 전처리 후, 확률적 경사 하강법을 제공하는 대표적인 분류용 클래스인 **SGDClassifier**를 가지고 오자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdrRKDxU__TE"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zg-X4THEbeE"
      },
      "source": [
        "- SGDClassifier의 객체를 만들 때는, 2개의 매개변수를 지정하게 된다.\n",
        "  - **loss**: 손실 함수의 종류 지정\n",
        "  - **max_iter**: 수행할 에포크 횟수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHH_gugTANEL",
        "outputId": "3b763f4d-43aa-4deb-e62f-e2c9fc1c199c"
      },
      "source": [
        "sc = SGDClassifier(loss = 'log', max_iter = 10, random_state = 42)\n",
        "sc.fit(train_scaled, train_target)\n",
        "print(sc.score(train_scaled, train_target))\n",
        "print(sc.score(test_scaled, test_target))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.773109243697479\n",
            "0.775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01OhWeg2E5Zp"
      },
      "source": [
        "- 출력된 훈련 세트와 테스트 세트의 정확도가 낮은걸로 보아, 지정한 반복 횟수 10번이 부족한 것으로 보인다.\n",
        "- 위에 나온 **ConvergenceWarning: Maximum number of iteration reached before convergence(수렴). Consider increasing max_iter to improve the fit.** 경고는 모델이 충분히 수렴하지 않았음을 나타내는 경고이다. max_iter 매개변수의 값을 늘려주는 것이 좋다.\n",
        "\n",
        "---\n",
        "\n",
        "- SGD는 점진적 학습이 가능하다.\n",
        "  - SGDClassifier 객체를 다시 만들지 않고, **partial_fit()** 메서드를 통해 이어서 훈련해본다.\n",
        "  - partial_fit() 메서드는 호출할 때마다 1 에포크씩 이어서 훈련한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnKFurZ6E0wU",
        "outputId": "6eae341b-5981-4a02-bb1a-07dc981d6747"
      },
      "source": [
        "sc.partial_fit(train_scaled, train_target)\n",
        "print(sc.score(train_scaled, train_target))\n",
        "print(sc.score(test_scaled, test_target))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8151260504201681\n",
            "0.825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu7lsPBEGOzC"
      },
      "source": [
        "- 에포크를 한 번 더 실행하니 정확도가 향상되었다.\n",
        "- 하지만 무작정 많이 반복할 수 없으니, 어떤 기준이 필요하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqCIWOqfGqbX"
      },
      "source": [
        "##3. 에포크와 과대/과소적합\n",
        "- 확률적 경사 하강법을 사용한 모델은 에포크 횟수에 따라 과소적합 혹은 과대적합이 될 수 있다.\n",
        "\n",
        "|에포크 횟수가 적은 경우|에포크 횟수가 많은 경우|\n",
        "|:-:|:-:|\n",
        "|모델이 훈련 세트를 덜 학습함|모델이 훈련 세트에 아주 잘 맞게 됨|\n",
        "|훈련 세트와 테스트 세트에 잘 맞지 않는 **과소적합** 모델일 가능성 존재|훈련 세트에 너무 잘 맞아서 테스트 세트에는 오히려 점수가 나쁜 **과대적합** 모델일 수 있음|\n",
        "\n",
        "- 과대적합이 시작하기 전에 훈련을 멈추는 것을 ***조기 종료**(early stopping)이라고 한다.\n",
        "\n",
        "---\n",
        "\n",
        "- 이 예제에서는 fit()메서드를 사용하지 않고, *partial_fit()* 메서드만 사용한다.\n",
        "  - partial_fit() 메서드만 사용하기 위해서는, 훈련 세트에 있는 전체 클래스의 레이블을 partial_fit() 메서드에 전달해주어야 한다.\n",
        "  - 이를 위해, np.unique() 함수로 train_target에 있는 7개 생선의 목록을 만들어준다.\n",
        "  - 에포크마다 훈련 세트와 테스트 세트의 점수를 기록하기 위해 2개의 리스트를 준비한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zN6cnxJGFxi"
      },
      "source": [
        "import numpy as np\n",
        "sc = SGDClassifier(loss = 'log', random_state = 42)\n",
        "train_score = []\n",
        "test_score = []\n",
        "\n",
        "classes = np.unique(train_target)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gqP16WIENcG",
        "outputId": "f7e03c57-452d-405f-a408-3fc726fc890b"
      },
      "source": [
        "classes"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Bream', 'Parkki', 'Perch', 'Pike', 'Roach', 'Smelt', 'Whitefish'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8rSre-zD9tD"
      },
      "source": [
        "#300번의 에포크 동안 훈련을 반복하여 진행한다.\n",
        "\n",
        "for _ in range(0, 300):\n",
        "  sc.partial_fit(train_scaled, train_target, classes = classes)\n",
        "  train_score.append(sc.score(train_scaled, train_target))\n",
        "  test_score.append(sc.score(test_scaled, test_target))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXJ7V3rSEZck"
      },
      "source": [
        "- Python의 **_** 는 특별한 변수이다. 나중에 사용하지 않고 그냥 버리는 값을 넣어두는 용도로 사용한다.\n",
        "\n",
        "--- \n",
        "\n",
        "300번의 에포크 동안 기록한 훈련 세트와 테스트 세트의 점수를 그래프로 그려보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "T90E9eimEXTQ",
        "outputId": "96faa57a-12c8-49ba-d4fa-55e931ba0d4b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_score) #파랑색\n",
        "plt.plot(test_score) #주황색\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y18Zxl13Bfvd"
      },
      "source": [
        "- 백 번째 에포크 이후에 훈련 세트와 테스트 세트의 점수가 조금씩 벌어지고 있다.\n",
        "- 에포크 초기에는 과소적합 되어 훈련 세트와 테스트 세트의 점수가 낮다.\n",
        "- 이 모델의 경우, 백 번째 에포크가 적절한 반복 횟수로 보인다.\n",
        "- 그럼 SGDClassifier의 반복 횟수를 100에 맞추고 모델을 다시 훈련해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iingQfhwFW2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed448e4-c693-4d91-9044-aedd730e33d7"
      },
      "source": [
        "sc = SGDClassifier(loss = 'log', max_iter = 100, tol = None, random_state = 42) \n",
        "#tol 매개변수에서 향상될 최솟값을 지정한다. tol 매개변수를 None으로 지정하여 자동으로 멈추지 않고 max_iter = 100만큼 무조건 반복하도록 만든다.\n",
        "sc.fit(train_scaled, train_target)\n",
        "print(sc.score(train_scaled, train_target))\n",
        "print(sc.score(test_scaled, test_target))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.957983193277311\n",
            "0.925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLGP9lIwC79k"
      },
      "source": [
        "- 최종 점수가 좋다.\n",
        "- 훈련 세트와 테스트 세트에서의 정확도 점수가 비교적 높게 나왔다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbMWPxoDCgE4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}