{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "혼자_공부하는_머신러닝_+_딥러닝_04_다양한_분류_알고리즘-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCoBLZ2/yjn7ORaFz4g95z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leena-GO/Self-study/blob/main/%ED%98%BC%EA%B3%B5%EB%A8%B8%EC%8B%A0/%ED%98%BC%EC%9E%90_%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%2B_%EB%94%A5%EB%9F%AC%EB%8B%9D_04_%EB%8B%A4%EC%96%91%ED%95%9C_%EB%B6%84%EB%A5%98_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkwY-88JKYM7"
      },
      "source": [
        "# 04-2 확률적 경사 하강법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEn-GcqqK48o"
      },
      "source": [
        "## 1. 점진적인 학습\n",
        "- 훈련 데이터가 한 번에 준비되지 않고 조금씩 전달이 된다면, 모델을 훈련시키는데 어려움이 생길 수 있다.\n",
        "- 이전에 훈련한 모델을 버리지 않고도 새로운 데이터에 대해 조금씩 훈련을 할 수 있는 방법을 **점진적 학습(온라인 학습)**이라고 한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw_Zr4zInDEb"
      },
      "source": [
        "### 1) 확률적 경사 하강법\n",
        "- 대표적인 점진적 학습 알고리즘은 **확률적 경사 하강법**(Stochastic Gradient Desent)이라고 한다.\n",
        "  -  *확률적* == *무작위하게, 랜덤하게*\n",
        "    - 훈련 세트를 사용하여 모델을 훈련하므로, 경사하강법도 훈련 세트를 사용해서 가장 가파른 길을 찾게 된다.\n",
        "    - 전체 샘플을 사용하지 않고 딱 하나의 샘플을 훈련 세트에서 랜덤하게 골라서 가장 가파른 길을 찾는다.\n",
        "  - *경사 == 기울기*\n",
        "  - *하강법 == 내려가는 방법*\n",
        "    - 가장 가파른 경사를 따라, 원하는 지점에 도달하는 것이 목표\n",
        "    - 하지만 조금씩 내려오는 것이 중요하다.\n",
        "    - 이렇게 내려오는 과정이 경사 하강법 모델을 훈련하는 것이다.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "- 정리하자면..\n",
        "  - 훈련 세트에서 랜덤하게 하나의 샘플을 선택해서, 가파른 경사를 조금 내려간다.\n",
        "  - 그다음 훈련 세트에서 랜덤하게 또 다른 샘플을 하나 선택하여 경사를 조금 내려간다.\n",
        "  - 이렇게 전체 샘플을 모두 사용할 때까지 계속 진행한다.\n",
        "  - 만약 경사를 다 내려가지 못했다면, 훈련 세트에 모든 샘플을 채워넣고, 경사를 처음부터 다시 내려가는데, 만족할만한 위치에 도달할 때까지 계속 내려간다.\n",
        "\n",
        "  - 확률적 경사 하강법에서 훈련 세트를 (한 번) 모두 사용하는 과정을 **에포크**(epoch)라고 한다.\n",
        "    - 일반적으로 경사 하강법은 수십, 수백 번 이상의 에포크를 수행한다. \n",
        "\n",
        "---\n",
        "\n",
        "- **미니배치 경사 하강법** (Minibatch gradient descent): 무작위로 몇 개의 샘플을 선택하여 경사를 내려가는 방법\n",
        "- **배치 경사 하강법**(Batch gradient descent): 극단적으로 한 번 경사로를 따라 이동하기 위해 전체 샘플을 사용하는 방법\n",
        "  - 전체 데이터를 사용하므로 가장 안정적인 방법\n",
        "  - 그렇지만 그만큼 컴퓨터 자원을 많이 사용하게 되고, 데이터가 너무 많아 한 번에 전체 데이터를 모두 읽지 못할수도 있다.\n",
        "\n",
        "---\n",
        "\n",
        "- 확률적 경사 하강법은 train set를 이용하여 최적의 장소로 조금씩 이동하는 알고리즘이다.\n",
        "- train data가 모두 준비되어 있지 않아도 학습을 매일 이어나갈 수 있다,\n",
        "- **신경망 모델**이 확률적 경사 하강법이나 미니배치 경사 하강법을 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JCPA9Elo1uZ"
      },
      "source": [
        "### 2) 손실 함수 (Loss function)\n",
        "- 어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지 측정하는 기준\n",
        "- 손실함수의 값이 작을수록 좋은 것이나, 어떤 값이 최솟값인지 알 수 없다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrWE84hseD6i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}